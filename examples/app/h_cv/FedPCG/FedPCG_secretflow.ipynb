{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FedPCG:一种利用聚类采样和全局原型的个性化联邦学习方法,基于隐语框架和FedNH baseline实现, reference:Dai, Y., Chen, Z., Li, J., Heinecke, S., Sun, L., & Xu, R. (2023, June). Tackling data heterogeneity in federated learning with class prototypes. In Proceedings of the AAAI Conference on Artificial Intelligence (Vol. 37, No. 6, pp. 7314-7322)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.1+cu118\n"
     ]
    }
   ],
   "source": [
    "import secretflow as sf\n",
    "from secretflow import PYUObject, proxy\n",
    "import os\n",
    "import yaml\n",
    "import sys\n",
    "import argparse\n",
    "import time\n",
    "import pickle\n",
    "import warnings\n",
    "import random\n",
    "import glob\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "from torch.distributions.multivariate_normal import MultivariateNormal\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "# from torch.backends.cudnn import benchmark as cudnn_benchmark\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import compress,product\n",
    "from PIL import Image\n",
    "from collections import OrderedDict, Counter\n",
    "from tqdm import tqdm\n",
    "from copy import deepcopy\n",
    "from scipy.cluster.hierarchy import fcluster, linkage\n",
    "global wandb_installed\n",
    "try:\n",
    "    import wandb\n",
    "    wandb_installed = True\n",
    "except ModuleNotFoundError:\n",
    "    wandb_installed = False\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "一些超参数设置，可以通过同级目录下的config.ini设置对应不同数据集的超参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(CReFF_crt_epoch=300, CReFF_lr_feature=0.1, CReFF_lr_net=0.01, CReFF_match_epoch=100, CReFF_num_of_fl_feature=100, Ditto_lambda=0.75, FedBABU_finetune_epoch=5, FedNH_client_adv_prototype_agg=False, FedNH_server_adv_prototype_agg=False, FedNH_smoothing=0.9, FedProto_lambda=0.1, FedROD_hyper_clf=True, FedROD_phead_separate=False, FedRep_head_epochs=10, beta='0.3', client_lr=0.01, client_lr_scheduler='diminishing', device='cpu', global_seed=0, keep_clients_model=False, no_norm=False, num_classes_per_client=None, num_clients=5, num_epochs=1, num_rounds=200, num_shards_per_client=None, optimizer='SGD', participate_ratio=0.6, partition='noniid-label-distribution', purpose='Cifar', sgd_momentum=0.9, sgd_weight_decay=1e-05, strategy='FedPCG', use_sam=False, use_wandb=False, yamlfile='./Cifar10_Conv2Cifar.yaml')\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import configparser\n",
    "\n",
    "def args_parser():\n",
    "    parser = argparse.ArgumentParser()\n",
    "\n",
    "    parser = argparse.ArgumentParser(description='Test Algorithms.')\n",
    "    # general settings\n",
    "    parser.add_argument('--purpose', default='experiments', type=str, help='purpose of this run')\n",
    "    parser.add_argument('--device', default='cuda:1', type=str, help='cuda device')\n",
    "    parser.add_argument('--global_seed', default=2022, type=int, help='Global random seed.')\n",
    "    parser.add_argument('--use_wandb', default=True, type=lambda x: (str(x).lower() in ['true', '1', 'yes']), help='Use wandb pkg')\n",
    "    parser.add_argument('--keep_clients_model', default=False, type=lambda x: (str(x).lower() in ['true', '1', 'yes']), help='Keep FedAVG local model')\n",
    "    # model architecture\n",
    "    parser.add_argument('--no_norm', default=False, type=lambda x: (str(x).lower() in ['true', '1', 'yes']), help='Use group/batch norm or not')\n",
    "    # optimizer\n",
    "    parser.add_argument('--optimizer', default='SGD', type=str, help='Optimizer')\n",
    "    parser.add_argument('--num_epochs', default=5, type=int, help='num local epochs')\n",
    "    parser.add_argument('--client_lr', default=0.1, type=float, help='client side initial learning rate')\n",
    "    parser.add_argument('--client_lr_scheduler', default='stepwise', type=str, help='client side learning rate update strategy')\n",
    "    parser.add_argument('--sgd_momentum', default=0.0, type=float, help='sgd momentum')\n",
    "    parser.add_argument('--sgd_weight_decay', default=1e-5, type=float, help='sgd weight decay')\n",
    "    parser.add_argument('--use_sam', default=False, type=lambda x: (str(x).lower() in ['true', '1', 'yes']), help='Use SAM optimizer')\n",
    "    # server config\n",
    "    parser.add_argument('--yamlfile', default=None, type=str, help='Configuration file.')\n",
    "    parser.add_argument('--strategy', default=None, type=str, help='strategy FL')\n",
    "    parser.add_argument('--num_clients', default=100, type=int, help='number of clients')\n",
    "    parser.add_argument('--num_rounds', default=200, type=int, help='number of communication rounds')\n",
    "    parser.add_argument('--participate_ratio', default=0.1, type=float, help='participate ratio')\n",
    "    parser.add_argument('--partition', default=None, type=str, help='method for partition the dataset')\n",
    "    parser.add_argument('--beta', default=None, type=str, help='Dirichlet Distribution parameter')\n",
    "    parser.add_argument('--num_classes_per_client', default=None, type=int, help='pathological non-iid parameter')\n",
    "    parser.add_argument('--num_shards_per_client', default=None, type=int, help='pathological non-iid parameter fedavg simulation')\n",
    "\n",
    "    # strategy parameters\n",
    "    parser.add_argument('--FedNH_smoothing', default=0.9, type=float, help='moving average parameters')\n",
    "    parser.add_argument('--FedNH_server_adv_prototype_agg', default=False, type=lambda x: (str(x).lower() in ['true', '1', 'yes']), help='FedNH server adv agg')\n",
    "    parser.add_argument('--FedNH_client_adv_prototype_agg', default=False, type=lambda x: (str(x).lower() in ['true', '1', 'yes']), help='FedNH client adv agg')\n",
    "\n",
    "    parser.add_argument('--FedROD_hyper_clf', default=True, type=lambda x: (str(x).lower() in ['true', '1', 'yes']), help='FedRod phead uses hypernetwork')\n",
    "    parser.add_argument('--FedROD_phead_separate', default=False, type=lambda x: (str(x).lower()\n",
    "                        in ['true', '1', 'yes']), help='FedROD phead separate train')\n",
    "    parser.add_argument('--FedProto_lambda', default=0.1, type=float, help='FedProto local penalty lambda')\n",
    "    parser.add_argument('--FedRep_head_epochs', default=10, type=int, help='FedRep local epochs to update head')\n",
    "    parser.add_argument('--FedBABU_finetune_epoch', default=5, type=int, help='FedBABU local epochs to finetune')\n",
    "    parser.add_argument('--Ditto_lambda', default=0.75, type=float, help='penalty parameter for Ditto')\n",
    "    parser.add_argument('--CReFF_num_of_fl_feature', default=100, type=int, help='num of federated feature per class')\n",
    "    parser.add_argument('--CReFF_match_epoch', default=100, type=int, help='epoch used to minmize gradient matching loss')\n",
    "    parser.add_argument('--CReFF_crt_epoch', default=300, type=int, help='epoch used to retrain classifier')\n",
    "    parser.add_argument('--CReFF_lr_net', default=0.01, type=float, help='lr for head')\n",
    "    parser.add_argument('--CReFF_lr_feature', default=0.1, type=float, help='lr for feature')\n",
    "\n",
    "    \n",
    "    arg_list = None\n",
    "    \n",
    "    config = configparser.ConfigParser()\n",
    "    config.read('config.ini')\n",
    "    # 其实是个字典: \n",
    "    # print(config['train']['batch_size'])\n",
    "    arg_list = []\n",
    "    for k, v in config['train'].items():\n",
    "        arg_list.append(\"--\"+k)\n",
    "        arg_list.append(v)\n",
    "\n",
    "    args = parser.parse_args(arg_list)\n",
    "    return args\n",
    "args = args_parser()\n",
    "print(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'strategy': 'FedPCG', 'num_rounds': 200, 'num_clients': 5, 'participate_ratio': 0.6, 'drop_ratio': 0.0, 'test_every': 1, 'split_testset': False, 'use_tqdm': False, 'dataset': 'Cifar10', 'partition': 'noniid-label-distribution', 'beta': '0.3', 'num_classes_per_client': None, 'num_shards_per_client': None, 'num_classes': 10, 'learning_rate': 1.0, 'lr_decay_per_round': 1.0, 'exclude': (), 'FedNH_smoothing': 0.9, 'FedNH_server_adv_prototype_agg': False, 'CReFF_num_of_fl_feature': 100, 'CReFF_match_epoch': 100, 'CReFF_lr_net': 0.01, 'CReFF_lr_feature': 0.1, 'CReFF_crt_epoch': 300, 'CReFF_dis_metric': 'ours'}\n",
      "{'model': 'Conv2Cifar', 'input_size': (3, 32, 32), 'num_classes': 10, 'num_epochs': 5, 'batch_size': 64, 'optimizer': 'SGD', 'learning_rate': 0.1, 'lr_scheduler': 'stepwise', 'lr_decay_per_round': 0.99, 'num_rounds': 200, 'use_tqdm': False, 'FedROD_hyper_clf': True, 'FedROD_phead_separate': False, 'FedNH_return_embedding': False, 'FedNH_head_init': 'orthogonal', 'FedNH_client_adv_prototype_agg': False, 'FedNH_fix_scaling': False, 'FedProto_lambda': 0.1, 'FedRep_head_epochs': 10, 'FedBABU_finetune_epoch': 5, 'Ditto_lambda': 0.75, 'CReFF_batch_real': 64, 'global_seed': 0, 'client_lr': 0.01, 'client_lr_scheduler': 'diminishing', 'sgd_momentum': 0.9, 'sgd_weight_decay': 1e-05, 'use_sam': False, 'no_norm': False}\n"
     ]
    }
   ],
   "source": [
    "def setup_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "use_wandb = wandb_installed and args.use_wandb\n",
    "setup_seed(args.global_seed)\n",
    "\n",
    "with open(args.yamlfile, \"r\",encoding='utf-8') as stream:\n",
    "    config = yaml.load(stream, Loader=yaml.Loader)\n",
    "\n",
    "# parse the default setting\n",
    "server_config = config['server_config']\n",
    "client_config = config['client_config']\n",
    "\n",
    "# overwrite with inputs\n",
    "server_config['strategy'] = args.strategy\n",
    "server_config['num_clients'] = args.num_clients\n",
    "server_config['num_rounds'] = args.num_rounds\n",
    "server_config['participate_ratio'] = args.participate_ratio\n",
    "server_config['partition'] = args.partition\n",
    "server_config['beta'] = args.beta\n",
    "server_config['num_classes_per_client'] = args.num_classes_per_client\n",
    "server_config['num_shards_per_client'] = args.num_shards_per_client\n",
    "client_config['num_rounds'] = args.num_rounds\n",
    "client_config['global_seed'] = args.global_seed\n",
    "client_config['optimizer'] = args.optimizer\n",
    "client_config['client_lr'] = args.client_lr\n",
    "client_config['client_lr_scheduler'] = args.client_lr_scheduler\n",
    "client_config['sgd_momentum'] = args.sgd_momentum\n",
    "client_config['sgd_weight_decay'] = args.sgd_weight_decay\n",
    "client_config['use_sam'] = args.use_sam\n",
    "client_config['no_norm'] = args.no_norm\n",
    "\n",
    "if server_config['partition'] == 'noniid-label-distribution':\n",
    "    partition_arg = f'beta:{args.beta}'\n",
    "elif server_config['partition'] == 'noniid-label-quantity':\n",
    "    partition_arg = f'num_classes_per_client:{args.num_classes_per_client}'\n",
    "elif server_config['partition'] == 'shards':\n",
    "    partition_arg = f'num_shards_per_client:{args.num_shards_per_client}'\n",
    "else:\n",
    "    raise ValueError('not implemented partition')\n",
    "print(server_config)\n",
    "print(client_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "客户端基类，主要用于联邦学习环境下各客户端的method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Client:\n",
    "    def __init__(self, criterion, trainset, testset, client_config, cid, **kwargs):\n",
    "        autoassign(locals())\n",
    "        if trainset is not None:\n",
    "            self.num_train_samples = len(trainset)\n",
    "        else:\n",
    "            self.num_train_samples = 0\n",
    "        if testset is not None:\n",
    "            self.num_test_samples = len(testset)\n",
    "        else:\n",
    "            self.num_test_samples = 0\n",
    "\n",
    "        if not torch.cuda.is_available():\n",
    "            self.device = \"cpu\"\n",
    "            print(\"cuda is not available. use cpu instead.\")\n",
    "        # wrap the trainset and testset with dataloader\n",
    "        self._prepare_data()\n",
    "        # local stats\n",
    "        self.num_rounds_particiapted = 0\n",
    "        self.train_loss_dict = OrderedDict()\n",
    "        self.train_acc_dict = OrderedDict()\n",
    "        self.test_loss_dict = OrderedDict()\n",
    "        self.test_acc_dict = OrderedDict()\n",
    "        # self.test_pfl_loss_dict = OrderedDict()\n",
    "        # self.test_pfl_acc_dict = OrderedDict()\n",
    "        self.new_state_dict = None\n",
    "\n",
    "    def _prepare_data(self):\n",
    "        self.label_dist = None\n",
    "        train_batchsize = min(self.client_config['batch_size'], self.num_train_samples)\n",
    "        test_batchsize = min(self.client_config['batch_size'] * 2, self.num_test_samples)\n",
    "\n",
    "        if self.num_train_samples > 0:\n",
    "            self.trainloader = DataLoader(self.trainset, batch_size=train_batchsize, shuffle=True)\n",
    "            # summarize training set label distribution\n",
    "            self.count_by_class = Counter(self.trainset.targets.numpy())\n",
    "            self.label_dist = {i: self.count_by_class[i] / self.num_train_samples for i in sorted(self.count_by_class.keys())}\n",
    "        else:\n",
    "            self.trainloader = None\n",
    "\n",
    "        if self.num_test_samples > 0:\n",
    "            self.testloader = DataLoader(self.testset, batch_size=test_batchsize, shuffle=False)\n",
    "            self.count_by_class_test = Counter(self.testset.targets.numpy())\n",
    "            self.label_dist_test = {i: self.count_by_class_test[i] / self.num_test_samples for i in sorted(self.count_by_class_test.keys())}\n",
    "        else:\n",
    "            self.testloader = None\n",
    "        # print(f\"Client{self.cid:3d} | total samples: {sum(self.count_by_class.values()):5d} | count by class: {self.count_by_class}\")\n",
    "\n",
    "    def set_params(self, model_state_dict, exclude_keys):\n",
    "        self.model.set_params(model_state_dict, exclude_keys)\n",
    "\n",
    "    def get_params(self):\n",
    "        return self.model.get_params()\n",
    "    def get_params_values(self):\n",
    "        return self.model.get_params_values()\n",
    "    def get_model_parameters(self):\n",
    "        return list(self.model.get_parameters())\n",
    "    \n",
    "    def get_model(self):\n",
    "        self.model.eval()\n",
    "        return self.model\n",
    "    def get_grads(self, dataloader):\n",
    "        return self.model.get_grads(dataloader)\n",
    "\n",
    "    def initialize_model(self):\n",
    "        raise NotImplementedError(\"Please write a method for the client to initialize the model(s).\")\n",
    "\n",
    "    def training(self, round, num_epochs):\n",
    "        raise NotImplementedError(\"Please write a training method for the client.\")\n",
    "\n",
    "    def testing(self, round, testloader=None):\n",
    "        \"\"\"\n",
    "            Provide testloader if one wants to use the externel testing dataset.\n",
    "        \"\"\"\n",
    "        raise NotImplementedError(\"Please write a testing method for the client.\")\n",
    "\n",
    "    def upload(self):\n",
    "        \"\"\"\n",
    "            Decide what information to share with the server\n",
    "        \"\"\"\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "服务器基类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_client_pyu = sf.PYU('fake_client')\n",
    "class Server:\n",
    "    def __init__(self,server_config, clients_dict, **kwargs):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "#         print('kwargs',**kwargs)\n",
    "        autoassign(locals())\n",
    "        self.server_model_state_dict = None\n",
    "        self.server_model_state_dict_best_so_far = None\n",
    "        self.num_clients = len(self.clients_dict)\n",
    "        self.strategy = None\n",
    "        self.average_train_loss_dict = {}\n",
    "        self.average_train_acc_dict = {}\n",
    "        # global model performance\n",
    "        self.gfl_test_loss_dict = {}\n",
    "        self.gfl_test_acc_dict = {}\n",
    "        # local model performance (averaged across all clients)\n",
    "        self.average_pfl_test_loss_dict = {}\n",
    "        self.average_pfl_test_acc_dict = {}\n",
    "        self.active_clients_indicies = None\n",
    "        self.rounds = 0\n",
    "#         # create a fake client on the server side; use for testing the performance of the global model\n",
    "#         # trainset is only used for creating the label distribution\n",
    "        self.server_side_client = kwargs['client_cstr'](\n",
    "            kwargs['server_side_criterion'],\n",
    "            kwargs['global_trainset'],\n",
    "            kwargs['global_testset'],\n",
    "            kwargs['server_side_client_config'],\n",
    "            -1,\n",
    "            device=fake_client_pyu,\n",
    "            **kwargs)\n",
    "\n",
    "    def select_clients(self, ratio):\n",
    "        assert ratio > 0.0, \"Invalid ratio. Possibly the server_config['participate_ratio'] is wrong.\"\n",
    "        num_clients = int(ratio * self.num_clients)\n",
    "        selected_indices = np.random.choice(range(self.num_clients), num_clients, replace=False)\n",
    "        return selected_indices\n",
    "\n",
    "    def testing(self, round, active_only, **kwargs):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def collect_stats(self, stage, round, active_only, **kwargs):\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def aggregate(self, client_uploads, round):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def run(self):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def save(self, filename, keep_clients_model=False):\n",
    "        if not keep_clients_model:\n",
    "            for client in self.clients_dict.values():\n",
    "                client.model = None\n",
    "                client.trainloader = None\n",
    "                client.trainset = None\n",
    "                client.new_state_dict = None\n",
    "        self.server_side_client.trainloader = None\n",
    "        self.server_side_client.trainset = None\n",
    "        self.server_side_client.testloader = None\n",
    "        self.server_side_client.testset = None\n",
    "        save_to_pkl(self, filename)\n",
    "\n",
    "    def summary_setup(self):\n",
    "        info = \"=\" * 30 + \"Run Summary\" + \"=\" * 30\n",
    "        info += \"\\nDataset:\\n\"\n",
    "        info += f\" dataset:{self.server_config['dataset']} | num_classes:{self.server_config['num_classes']}\"\n",
    "        partition = self.server_config['partition']\n",
    "        info += f\" | partition:{self.server_config['partition']}\"\n",
    "        if partition == 'iid-equal-size':\n",
    "            info += \"\\n\"\n",
    "        elif partition in ['iid-diff-size', 'noniid-label-distribution']:\n",
    "            info += f\" | beta:{self.server_config['beta']}\\n\"\n",
    "        elif partition == 'noniid-label-quantity':\n",
    "            info += f\" | num_classes_per_client:{self.server_config['num_classes_per_client']}\\n \"\n",
    "        else:\n",
    "            if 'shards' in partition.split('-'):\n",
    "                pass\n",
    "            else:\n",
    "                raise ValueError(f\" Invalid dataset partition strategy:{partition}!\")\n",
    "        info += \"Server Info:\\n\"\n",
    "        info += f\" strategy:{self.server_config['strategy']} | num_clients:{self.server_config['num_clients']} | num_rounds: {self.server_config['num_rounds']}\"\n",
    "        info += f\" | participate_ratio:{self.server_config['participate_ratio']} | drop_ratio:{self.server_config['drop_ratio']}\\n\"\n",
    "        info += f\"Clients Info:\\n\"\n",
    "#         print('clients_dict',clients_dict[0])\n",
    "#         client_config = self.clients_dict[0].client_config\n",
    "#         client_config = client_config\n",
    "        info += f\" model:{client_config['model']} | num_epochs:{client_config['num_epochs']} | batch_size:{client_config['batch_size']}\"\n",
    "        info += f\" | optimizer:{client_config['optimizer']} | inint lr:{client_config['client_lr']} | lr scheduler:{client_config['client_lr_scheduler']} | momentum: {client_config['sgd_momentum']} | weight decay: {client_config['sgd_weight_decay']}\"\n",
    "        print(info)\n",
    "#         mdict = self.server_side_client.get_params()\n",
    "# #         mdict_values = self.server_side_client.get_params_values()\n",
    "#         print('mdict',mdict)\n",
    "#         print(f\" {client_config['model']}: size:{calculate_model_size(mdict):.3f} MB | num params:{sum(mdict[key].nelement() for key in mdict) / 1e6: .3f} M\")\n",
    "\n",
    "    def summary_result(self):\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "分类任务模型架构"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    \"\"\"For classification problem\"\"\"\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "\n",
    "    def get_params(self):\n",
    "        return self.state_dict()\n",
    "    def get_parameters(self):\n",
    "        return self.parameters()\n",
    "    \n",
    "    def get_gradients(self, dataloader):\n",
    "        raise NotImplementedErrorm\n",
    "\n",
    "    def set_params(self, model_state_dict, exclude_keys=set()):\n",
    "        \"\"\"\n",
    "            Reference: Be careful with the state_dict[key].\n",
    "            https://discuss.pytorch.org/t/how-to-copy-a-modified-state-dict-into-a-models-state-dict/64828/4.\n",
    "        \"\"\"\n",
    "        with torch.no_grad():\n",
    "            for key in model_state_dict.keys():\n",
    "                if key not in exclude_keys:\n",
    "                    self.state_dict()[key].copy_(model_state_dict[key])\n",
    "\n",
    "\n",
    "class ModelWrapper(Model):\n",
    "    def __init__(self, base, head, config):\n",
    "        \"\"\"\n",
    "            head and base should be nn.module\n",
    "        \"\"\"\n",
    "        super(ModelWrapper, self).__init__(config)\n",
    "\n",
    "        self.base = base\n",
    "        self.head = head\n",
    "\n",
    "    def forward(self, x, return_embedding):\n",
    "        feature_embedding = self.base(x)\n",
    "        out = self.head(feature_embedding)\n",
    "        if return_embedding:\n",
    "            return feature_embedding, out\n",
    "        else:\n",
    "            return out\n",
    "        \n",
    "class Conv2Cifar(Model):\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=64, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=5)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.linear1 = nn.Linear(64 * 5 * 5, 384)\n",
    "        self.linear2 = nn.Linear(384, 192)\n",
    "        # intentionally remove the bias term for the last linear layer for fair comparison\n",
    "        self.prototype = nn.Linear(192, config['num_classes'], bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 64 * 5 * 5)\n",
    "        x = F.relu(self.linear1(x))\n",
    "        x = F.relu(self.linear2(x))\n",
    "        logits = self.prototype(x)\n",
    "        return logits\n",
    "\n",
    "    def get_embedding(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 64 * 5 * 5)\n",
    "        x = F.relu(self.linear1(x))\n",
    "        x = F.relu(self.linear2(x))\n",
    "        logits = self.prototype(x)\n",
    "        return x, logits\n",
    "\n",
    "class Conv2CifarNH(Model):\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "        self.return_embedding = config['FedNH_return_embedding']\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=64, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=5)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.linear1 = nn.Linear(64 * 5 * 5, 384)\n",
    "        self.linear2 = nn.Linear(384, 192)\n",
    "        temp = nn.Linear(192, config['num_classes'], bias=False).state_dict()['weight']\n",
    "        self.prototype = nn.Parameter(temp)\n",
    "        self.scaling = torch.nn.Parameter(torch.tensor([1.0]))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 64 * 5 * 5)\n",
    "        x = F.relu(self.linear1(x))\n",
    "        feature_embedding = F.relu(self.linear2(x))\n",
    "        feature_embedding_norm = torch.norm(feature_embedding, p=2, dim=1, keepdim=True).clamp(min=1e-12)\n",
    "        feature_embedding = torch.div(feature_embedding, feature_embedding_norm)\n",
    "        if self.prototype.requires_grad == False:\n",
    "            normalized_prototype = self.prototype\n",
    "        else:\n",
    "            prototype_norm = torch.norm(self.prototype, p=2, dim=1, keepdim=True).clamp(min=1e-12)\n",
    "            normalized_prototype = torch.div(self.prototype, prototype_norm)\n",
    "        logits = torch.matmul(feature_embedding, normalized_prototype.T)\n",
    "        logits = self.scaling * logits\n",
    "\n",
    "        if self.return_embedding:\n",
    "            return feature_embedding, logits\n",
    "        else:\n",
    "            return logits\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "基于head层相似度的聚类采样"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClientSelection:\n",
    "    def __init__(self, total, device=\"cpu\"):\n",
    "        self.total = total\n",
    "        self.device = device\n",
    "\n",
    "    def select(self, n, client_idxs, metric):\n",
    "        pass\n",
    "\n",
    "    def save_selected_clients(self, client_idxs, results):\n",
    "        tmp = np.zeros(self.total)\n",
    "        tmp[client_idxs] = 1\n",
    "        tmp.tofile(results, sep=',')\n",
    "        results.write(\"\\n\")\n",
    "\n",
    "    def save_results(self, arr, results, prefix=''):\n",
    "        results.write(prefix)\n",
    "        np.array(arr).astype(np.float32).tofile(results, sep=',')\n",
    "        results.write(\"\\n\")\n",
    "\n",
    "\n",
    "'''Clustered Sampling Algorithm 1'''\n",
    "class ClusteredSampling1(ClientSelection):\n",
    "    def __init__(self, total, device, n_cluster):\n",
    "        super().__init__(total, device)\n",
    "        self.n_cluster = n_cluster\n",
    "\n",
    "    def setup(self, n_samples):\n",
    "        '''\n",
    "        Since clustering is performed according to the clients sample size n_i,\n",
    "        unless n_i changes during the learning process,\n",
    "        Algo 1 needs to be run only once at the beginning of the learning process.\n",
    "        '''\n",
    "        epsilon = int(10 ** 10)\n",
    "        client_ids = sorted(n_samples.keys())\n",
    "        n_samples = np.array([n_samples[i] for i in client_ids])\n",
    "        weights = n_samples / np.sum(n_samples)\n",
    "        # associate each client to a cluster\n",
    "        augmented_weights = np.array([w * self.n_cluster * epsilon for w in weights])\n",
    "        ordered_client_idx = np.flip(np.argsort(augmented_weights))\n",
    "\n",
    "        distri_clusters = np.zeros((self.n_cluster, self.total)).astype(int)\n",
    "        k = 0\n",
    "        for client_idx in ordered_client_idx:\n",
    "            while augmented_weights[client_idx] > 0:\n",
    "                sum_proba_in_k = np.sum(distri_clusters[k])\n",
    "                u_i = min(epsilon - sum_proba_in_k, augmented_weights[client_idx])\n",
    "                distri_clusters[k, client_idx] = u_i\n",
    "                augmented_weights[client_idx] += -u_i\n",
    "                sum_proba_in_k = np.sum(distri_clusters[k])\n",
    "                if sum_proba_in_k == 1 * epsilon:\n",
    "                    k += 1\n",
    "\n",
    "        distri_clusters = distri_clusters.astype(float)\n",
    "        for l in range(self.n_cluster):\n",
    "            distri_clusters[l] /= np.sum(distri_clusters[l])\n",
    "\n",
    "        self.distri_clusters = distri_clusters\n",
    "\n",
    "\n",
    "    def select(self, n, client_idxs, metric=None):\n",
    "        #selected_client_idxs = [int(np.random.choice(self.total, 1, p=self.distri_clusters[k])) for k in range(n)]\n",
    "        selected_client_idxs = []\n",
    "        for k in range(n):\n",
    "            weight = np.take(self.distri_clusters[k], client_idxs)\n",
    "            selected_client_idxs.append(int(np.random.choice(client_idxs, 1, p=weight/sum(weight))))\n",
    "        return np.array(selected_client_idxs)\n",
    "    \n",
    "    \n",
    "def add_and_div(samples):\n",
    "    return samples / sum(samples)\n",
    "## clients_dict[0]['num_train_samples']\n",
    "\n",
    "'''Clustered Sampling Algorithm 2'''\n",
    "class ClusteredSampling2(ClientSelection):\n",
    "    def __init__(self, total, device, dist):\n",
    "        super().__init__(total, device)\n",
    "        self.distance_type = dist\n",
    "\n",
    "    def setup(self, n_samples):\n",
    "        \"\"\"\n",
    "        return the `representative gradient` formed by the difference\n",
    "        between the local work and the sent global model\n",
    "        \"\"\"\n",
    "        client_ids = sorted(n_samples.keys())\n",
    "        n_samples = np.array([n_samples[i] for i in client_ids])\n",
    "        print('n_samples',n_samples)\n",
    "        self.weights = n_samples / sum(n_samples)\n",
    "#         self.weights = server_pyu(add_and_div)(n_samples)\n",
    "\n",
    "    def init(self, global_m, local_models):\n",
    "        self.prev_global_m = global_m\n",
    "        self.gradients = self.get_gradients(global_m, local_models)\n",
    "\n",
    "    def select(self, n, client_idxs, metric=None):\n",
    "        # GET THE CLIENTS' SIMILARITY MATRIX\n",
    "        sim_matrix = self.get_matrix_similarity_from_grads(\n",
    "            self.gradients, distance_type=self.distance_type)\n",
    "        # GET THE DENDROGRAM TREE ASSOCIATED\n",
    "        linkage_matrix = linkage(sim_matrix, \"ward\")\n",
    "\n",
    "        distri_clusters = self.get_clusters_with_alg2(linkage_matrix, n, self.weights)\n",
    "        # sample clients\n",
    "        selected_client_idxs = np.zeros(n, dtype=int)\n",
    "        for k in range(n):\n",
    "            selected_client_idxs[k] = int(np.random.choice(client_idxs, 1, p=distri_clusters[k]))\n",
    "            #weight = np.take(distri_clusters[k], client_idxs)\n",
    "            #selected_client_idxs[k] = int(np.random.choice(client_idxs, 1, p=weight/sum(weight)))\n",
    "        #selected_client_idxs = np.take(client_idxs, selected_client_idxs)\n",
    "        return selected_client_idxs\n",
    "\n",
    "    def update(self, clients_models, sampled_clients_for_grad):\n",
    "        print('>> update gradients')\n",
    "        # UPDATE THE HISTORY OF LATEST GRADIENT\n",
    "        gradients_i = self.get_gradients(self.prev_global_m, clients_models)\n",
    "        for idx, gradient in zip(sampled_clients_for_grad, gradients_i):\n",
    "            self.gradients[idx] = gradient\n",
    "\n",
    "    def get_gradients(self, global_m, local_models):\n",
    "        \"\"\"\n",
    "        return the `representative gradient` formed by the difference\n",
    "        between the local work and the sent global model\n",
    "        \"\"\"\n",
    "        local_model_params = []\n",
    "#         print('local_models',sf.reveal(local_models))\n",
    "        for model in local_models:\n",
    "            local_model_params += [[tens.detach().to(self.device) for tens in list(sf.reveal(model).parameters())][0]] #.numpy()\n",
    "\n",
    "        global_model_params = [tens.detach().to(self.device) for tens in list(sf.reveal(global_m).values())][0]\n",
    "\n",
    "        local_model_grads = []\n",
    "        for local_params in local_model_params:\n",
    "            local_model_grads += [[local_weights - global_weights\n",
    "                                   for local_weights, global_weights in\n",
    "                                   zip(local_params, global_model_params)]]\n",
    "\n",
    "        return local_model_grads\n",
    "\n",
    "    def get_matrix_similarity_from_grads(self, local_model_grads, distance_type):\n",
    "        \"\"\"\n",
    "        return the similarity matrix where the distance chosen to\n",
    "        compare two clients is set with `distance_type`\n",
    "        \"\"\"\n",
    "        n_clients = len(local_model_grads)\n",
    "\n",
    "        #metric_matrix = np.zeros((n_clients, n_clients))\n",
    "        metric_matrix = torch.zeros((n_clients, n_clients))\n",
    "        for i, j in tqdm(product(range(n_clients), range(n_clients)), desc='>> similarity', ncols=80):\n",
    "            metric_matrix[i, j] = self.get_similarity(\n",
    "                local_model_grads[i], local_model_grads[j], distance_type)\n",
    "\n",
    "        return metric_matrix\n",
    "\n",
    "    def get_similarity(self, grad_1, grad_2, distance_type=\"L1\"):\n",
    "        if distance_type == \"L1\":\n",
    "            norm = 0\n",
    "            for g_1, g_2 in zip(grad_1, grad_2):\n",
    "                #norm += np.sum(np.abs(g_1 - g_2))\n",
    "                norm += torch.sum(torch.abs(g_1 - g_2))\n",
    "            return norm.cpu().data\n",
    "\n",
    "        elif distance_type == \"L2\":\n",
    "            norm = 0\n",
    "            for g_1, g_2 in zip(grad_1, grad_2):\n",
    "                norm += np.sum((g_1 - g_2) ** 2)\n",
    "            return norm\n",
    "\n",
    "        elif distance_type == \"cosine\":\n",
    "            norm, norm_1, norm_2 = 0, 0, 0\n",
    "            print(grad_1[0].squeeze().shape, grad_2[0].squeeze().shape)\n",
    "            for i in range(len(grad_1)):\n",
    "                norm += np.sum(torch.mul(grad_1[i].squeeze(), grad_2[i].squeeze()))\n",
    "                norm_1 += np.sum(grad_1[i] ** 2)\n",
    "                norm_2 += np.sum(grad_2[i] ** 2)\n",
    "\n",
    "            if norm_1 == 0.0 or norm_2 == 0.0:\n",
    "                return 0.0\n",
    "            else:\n",
    "                norm /= np.sqrt(norm_1 * norm_2)\n",
    "                return np.arccos(norm)\n",
    "\n",
    "    def get_clusters_with_alg2(self, linkage_matrix: np.array, n_sampled: int, weights: np.array):\n",
    "        \"\"\"Algorithm 2\"\"\"\n",
    "        epsilon = int(10 ** 10)\n",
    "\n",
    "        # associate each client to a cluster\n",
    "        link_matrix_p = deepcopy(linkage_matrix)\n",
    "        augmented_weights = deepcopy(weights)\n",
    "\n",
    "        for i in range(len(link_matrix_p)):\n",
    "            idx_1, idx_2 = int(link_matrix_p[i, 0]), int(link_matrix_p[i, 1])\n",
    "\n",
    "            new_weight = np.array(\n",
    "                [sf.reveal(augmented_weights)[idx_1] + sf.reveal(augmented_weights)[idx_2]])\n",
    "            augmented_weights = np.concatenate((augmented_weights, new_weight))\n",
    "            link_matrix_p[i, 2] = int(new_weight * epsilon)\n",
    "\n",
    "        clusters = fcluster(\n",
    "            link_matrix_p, int(epsilon / n_sampled), criterion=\"distance\")\n",
    "\n",
    "        n_clients, n_clusters = len(clusters), len(set(clusters))\n",
    "\n",
    "        # Associate each cluster to its number of clients in the cluster\n",
    "        pop_clusters = np.zeros((n_clusters, 2),dtype=np.int64)\n",
    "        for i in range(n_clusters):\n",
    "            pop_clusters[i, 0] = i + 1\n",
    "            for client in np.where(clusters == i + 1)[0]:\n",
    "                pop_clusters[i, 1] += int(weights[client] * epsilon * n_sampled)\n",
    "\n",
    "        pop_clusters = pop_clusters[pop_clusters[:, 1].argsort()]\n",
    "\n",
    "        distri_clusters = np.zeros((n_sampled, n_clients), dtype=np.int64)\n",
    "\n",
    "        # n_sampled biggest clusters that will remain unchanged\n",
    "        kept_clusters = pop_clusters[n_clusters - n_sampled :, 0]\n",
    "\n",
    "        for idx, cluster in enumerate(kept_clusters):\n",
    "            for client in np.where(clusters == cluster)[0]:\n",
    "                distri_clusters[idx, client] = int(\n",
    "                    weights[client] * n_sampled * epsilon)\n",
    "\n",
    "        k = 0\n",
    "        for j in pop_clusters[: n_clusters - n_sampled, 0]:\n",
    "            clients_in_j = np.where(clusters == j)[0]\n",
    "            np.random.shuffle(clients_in_j)\n",
    "\n",
    "            for client in clients_in_j:\n",
    "                weight_client = int(weights[client] * epsilon * n_sampled)\n",
    "\n",
    "                while weight_client > 0:\n",
    "                    sum_proba_in_k = np.sum(distri_clusters[k])\n",
    "                    u_i = min(epsilon - sum_proba_in_k, weight_client)\n",
    "                    distri_clusters[k, client] = u_i\n",
    "                    weight_client += -u_i\n",
    "                    sum_proba_in_k = np.sum(distri_clusters[k])\n",
    "                    if sum_proba_in_k == 1 * epsilon:\n",
    "                        k += 1\n",
    "\n",
    "        distri_clusters = distri_clusters.astype(float)\n",
    "        print(distri_clusters.shape)\n",
    "        for l in range(n_sampled):\n",
    "            distri_clusters[l] /= np.sum(distri_clusters[l])\n",
    "\n",
    "        return distri_clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "工具函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {},
   "outputs": [],
   "source": [
    "def autoassign(lcls):\n",
    "    \"\"\"\n",
    "        Map all inputs to class attributes.\n",
    "        Reference: https://stackoverflow.com/questions/3652851/what-is-the-best-way-to-do-automatic-attribute-assignment-in-python-and-is-it-a\n",
    "    \"\"\"\n",
    "    for key in lcls.keys():\n",
    "        if key != \"self\":\n",
    "            # flattern kwargs\n",
    "            if key == 'kwargs':\n",
    "                if key in lcls[\"self\"].__dict__:\n",
    "                    for k in lcls[\"self\"].__dict__[key]:\n",
    "                        lcls[\"self\"].__dict__[\n",
    "                            k] = lcls[\"self\"].__dict__[key][k]\n",
    "            else:\n",
    "                lcls[\"self\"].__dict__[key] = lcls[key]\n",
    "\n",
    "def calculate_model_size(model_state_dict):\n",
    "    \"\"\"Show model size in MB\"\"\"\n",
    "    # mem_params = sum([param.nelement() * param.element_size()\n",
    "    #                   for param in model.parameters()])\n",
    "    # mem_bufs = sum([buf.nelement() * buf.element_size()\n",
    "    #                 for buf in model.buffers()])\n",
    "    # mem = mem_params + mem_bufs  # in bytes\n",
    "    mdict = model_state_dict\n",
    "    mem = sum([mdict[key].nelement() * mdict[key].element_size()\n",
    "               for key in mdict.keys()])\n",
    "    return mem * 1e-6\n",
    "\n",
    "def calculate_flops(model, inputs_size, device):\n",
    "    \"\"\"inputs_size: bacth size 1 input\"\"\"\n",
    "    stat = summary(model, inputs_size, verbose=0, device=device)\n",
    "    return stat.total_mult_adds\n",
    "\n",
    "\n",
    "def save_to_pkl(obj, path):\n",
    "    with open(path, 'wb') as file:\n",
    "        pickle.dump(obj, file, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "\n",
    "def load_from_pkl(path):\n",
    "    with open(path, 'rb') as file:\n",
    "        data = pickle.load(file)\n",
    "    return data\n",
    "\n",
    "\n",
    "def mkdirs(dirpath):\n",
    "    if not os.path.exists(dirpath):\n",
    "        # multi-threading\n",
    "        os.makedirs(dirpath, exist_ok=True)\n",
    "\n",
    "\n",
    "def access_last_added_element(ordered_dict):\n",
    "    \"\"\"\n",
    "        next(reversed(ordered_dict)) returns the last added key\n",
    "    \"\"\"\n",
    "    try:\n",
    "        key = next(reversed(ordered_dict))\n",
    "        return ordered_dict[key]\n",
    "    except StopIteration:\n",
    "        # print(\"The OrderedDict is empty.\")\n",
    "        return None\n",
    "\n",
    "\n",
    "class Initializer:\n",
    "    \"\"\"\n",
    "        ref: \n",
    "        1. https://github.com/3ammor/Weights-Initializer-pytorch/blob/master/weight_initializer.py\n",
    "        2. https://github.com/kevinzakka/pytorch-goodies\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    @staticmethod\n",
    "    def initialize(model, initialization, **kwargs):\n",
    "        def weights_init(m):\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                initialization(m.weight.data, **kwargs)\n",
    "                try:\n",
    "                    initialization(m.bias.data)\n",
    "                except:\n",
    "                    pass\n",
    "\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                initialization(m.weight.data, **kwargs)\n",
    "                try:\n",
    "                    initialization(m.bias.data)\n",
    "                except:\n",
    "                    pass\n",
    "        model.apply(weights_init)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Split Datasets\n",
    "\n",
    "References:\n",
    "1. https://github.com/Xtra-Computing/NIID-Bench\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "class DatasetSplit(Dataset):\n",
    "    \"\"\"An abstract Dataset class wrapped around Pytorch Dataset class.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, dataset, idxs):\n",
    "        self.dataset = dataset\n",
    "        self.idxs = [int(i) for i in idxs]\n",
    "        self.targets = dataset.targets[self.idxs]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.idxs)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        image, label = self.dataset[self.idxs[item]]\n",
    "        # return torch.tensor(image), torch.tensor(label)\n",
    "        return image, label\n",
    "\n",
    "\n",
    "def remove_by_class(trainset, list_of_classes_to_remove):\n",
    "    for cls in list_of_classes_to_remove:\n",
    "        selected = trainset.targets != cls\n",
    "        trainset.idxs = list(compress(trainset.idxs, selected))\n",
    "        trainset.targets = trainset.dataset.targets[trainset.idxs]\n",
    "    return trainset\n",
    "\n",
    "\n",
    "def split_trainset_by_class(client_trainset):\n",
    "    \"\"\"\n",
    "    Input: client_trainset, which is an object of DatasetSplit class\n",
    "    Return: a dictionary of trainset, where the key is the label while the value is an object of the DatasetSplit class\n",
    "    \"\"\"\n",
    "    all_classes = torch.unique(client_trainset.targets).tolist()\n",
    "    class_dataset_dict = {}\n",
    "    for c in all_classes:\n",
    "        selected = client_trainset.targets == c\n",
    "        idx_c = list(compress(client_trainset.idxs, selected))\n",
    "        class_dataset_dict[c] = DatasetSplit(client_trainset.dataset, idx_c)\n",
    "    return class_dataset_dict\n",
    "\n",
    "\n",
    "def sampler(dataset, num_clients, partition, seed=None, minsize=10, **kwargs):\n",
    "    \"\"\"\n",
    "        dataset: torch.utils.data.Dataset object\n",
    "        partition:\n",
    "            iid-equal-size: \n",
    "                uniformly randomly sample from the whole datasets and each party approximately has the same number of samples.\n",
    "\n",
    "            iid-diff-size: \n",
    "                uniformly randomly sample from the whole datasets but each party approximately has different number of samples; \n",
    "                should also set the beta parameter.\n",
    "\n",
    "            noniid-label-quantity:\n",
    "                Each client will only contain `num_classes_per_client` classes of samples; for any two clients that have the same class, the samples will not overlap;\n",
    "                should also set the num_class, num_classes_per_client, and ylabels parameters.\n",
    "                samples in each classes are uniformly diveded. But this could still lead to class imbalance in each client.\n",
    "                See https://arxiv.org/pdf/2102.02079.pdf a) Quantity-based label imbalance\n",
    "\n",
    "            noniid-label-distribution:\n",
    "                The number of classes per client own follow a dirichlet distribution with concentration parameter beta.\n",
    "                should also set the num_class, beta, and ylabels parameters.\n",
    "\n",
    "            shards:\n",
    "                Suppose there are (n clients, c classes, N datapoints) and each clients own s shards of data. Then the \n",
    "                number of data per shard is  size_s = N / (n * s). And each class is split into c/size_s shards.\n",
    "                Shards are randomly assigned to clients.\n",
    "\n",
    "        kwargs:\n",
    "            beta: concentration parameter for the **symmetric** Dirichlet distribution; float, larger than 0\n",
    "            ylabels: 1d tensor of size as the len(dataset)\n",
    "            num_class: int; larger than 0\n",
    "            num_classes_per_client: int;  larger than 0 smaller than total number of classes in ylabels           \n",
    "\n",
    "        Return: a dict; {cid: torch.utils.data.Dataset object}\n",
    "\n",
    "        --- Notes ---\n",
    "        Effect of the beta parameter:\n",
    "            When beta = 1, the symmetric Dirichlet distribution is equivalent to a uniform distribution over the open standard (K − 1)-simplex, (the distribution over distributions is uniform)\n",
    "            When beta > 1, it prefers variates that are dense, evenly distributed distributions, i.e. all the values within a single sample are similar to each other. \n",
    "            When beta < 1, it prefers sparse distributions, i.e. most of the values within a single sample will be close to 0, and the vast majority of the mass will be concentrated in a few of the values.\n",
    "\n",
    "        --- References ---\n",
    "        1. https://en.wikipedia.org/wiki/Dirichlet_distribution#The_concentration_parameter\n",
    "    \"\"\"\n",
    "    # process arguments\n",
    "    if partition in ['iid-diff-size', 'noniid-label-distribution']:\n",
    "        if 'beta' not in kwargs:\n",
    "            beta = 0.5\n",
    "            warnings.warn(\n",
    "                f\"partition:{partition} | beta is not provided. Set to 0.5.\")\n",
    "        else:\n",
    "            beta = kwargs['beta']\n",
    "            temp = beta.split('b')\n",
    "            if len(temp) == 1:\n",
    "                beta = float(temp[0])\n",
    "                is_balanced = False\n",
    "            elif len(temp) == 2:\n",
    "                beta = float(temp[0])\n",
    "                is_balanced = True\n",
    "            assert beta > 0, \"beta needs to be non-negative\"\n",
    "    if partition == 'shards':\n",
    "        if 'num_shards_per_client' not in kwargs:\n",
    "            raise ValueError(\n",
    "                f\"The num_shards_per_client parameter needs to be set for the partition {partition}.\")\n",
    "        else:\n",
    "            num_classes = kwargs['num_classes']\n",
    "\n",
    "    if partition in ['noniid-label-quantity', 'noniid-label-distribution']:\n",
    "        if 'num_classes' not in kwargs:\n",
    "            raise ValueError(\n",
    "                f\"The num_classes parameter needs to be set for the partition {partition}.\")\n",
    "        else:\n",
    "            num_classes = kwargs['num_classes']\n",
    "        try:\n",
    "            num_unique_class = len(torch.unique(dataset.targets))\n",
    "        except TypeError:\n",
    "            print('dataset.targets is not of tensor type! Proper actions are required.')\n",
    "            exit()\n",
    "        assert num_classes == num_unique_class, f\"num_classes is set to {num_classes}, but number of unique class detected in ylables are {num_unique_class}.\"\n",
    "        if 'ylabels' not in kwargs:\n",
    "            raise ValueError(\n",
    "                f\"The ylabels parameter needs to be set for the partition {partition}.\")\n",
    "        else:\n",
    "            ylabels = kwargs['ylabels']\n",
    "    if seed is not None:\n",
    "        np.random.seed(seed)\n",
    "    num_samples = len(dataset)\n",
    "    idxs = np.random.permutation(num_samples)\n",
    "    cur_minsize = 0\n",
    "    attemp = 0\n",
    "    max_attemp = 3\n",
    "    stats_dict = {}\n",
    "    if partition == 'iid-equal-size':\n",
    "        batch_idxs = np.array_split(idxs, num_clients)\n",
    "        if len(batch_idxs[-1]) < minsize:\n",
    "            warnings.warn(\n",
    "                f\"partition:{partition} | Some clients have less than {minsize} samples. Check it before continue.\")\n",
    "        cid_idxlst_dict = {\n",
    "            cid: batch_idxs[cid].tolist() for cid in range(num_clients)}\n",
    "    elif partition == 'iid-diff-size':\n",
    "        \"\"\"\n",
    "        The number of samples per client follow a dirichlet distribution with concentration parameter beta.\n",
    "        But the number of samples per classes in each client are approxumately the same\n",
    "        \"\"\"\n",
    "        while cur_minsize < minsize:\n",
    "            attemp += 1\n",
    "            if attemp == max_attemp:\n",
    "                raise RuntimeError(\n",
    "                    f\"partition:{partition} | Exceeds max allowed attempts. Consider change the random seed.\")\n",
    "            proportions = np.random.dirichlet(np.repeat(beta, num_clients))\n",
    "            proportions = proportions / proportions.sum()\n",
    "            cur_minsize = np.min(proportions * len(idxs))\n",
    "\n",
    "        proportions_to_num = (np.cumsum(proportions) * len(idxs)).astype(int)[:-1]\n",
    "        batch_idxs = np.split(idxs, proportions_to_num)\n",
    "        cid_idxlst_dict = {i: batch_idxs[i].tolist() for i in range(num_clients)}\n",
    "        stats_dict['proportions'] = proportions\n",
    "    elif partition == 'noniid-label-quantity':\n",
    "        \"\"\"\n",
    "        Each client will only contain `num_classes_per_client` classes of samples.\n",
    "        For any two clients that have the same class, the samples will not overlap.\n",
    "        \"\"\"\n",
    "        # use user supplied partition\n",
    "        if 'assigned_clients_per_class' in kwargs and 'assigned_classes_per_client' in kwargs:\n",
    "            assigned_clients_per_class = kwargs['assigned_clients_per_class']\n",
    "            assigned_classes_per_client = kwargs['assigned_classes_per_client']\n",
    "            assert type(assigned_clients_per_class) == list, \"assigned_clients_per_class has to a list\"\n",
    "            assert type(assigned_classes_per_client) == list, \"assigned_classes_per_client has to a list\"\n",
    "            assert type(assigned_classes_per_client[0]) == set, \"the elements of assigned_classes_per_client has to a set\"\n",
    "            cid_idxlst_dict = {cid: [] for cid in range(num_clients)}\n",
    "            num_classes_per_client = [len(s) for s in assigned_classes_per_client]\n",
    "        else:\n",
    "            if 'num_classes_per_client' not in kwargs:\n",
    "                raise ValueError(f\"The num_classes_per_client parameter needs to be set for the partition {partition}.\")\n",
    "            else:\n",
    "                num_classes_per_client = kwargs['num_classes_per_client']\n",
    "            assert num_classes_per_client <= num_classes, \"`num_classes_per_client` should be no bigger than `num_classes`\"\n",
    "            cid_idxlst_dict = {cid: [] for cid in range(num_clients)}\n",
    "            assigned_clients_per_class = [0 for i in range(num_classes)]\n",
    "            assigned_classes_per_client = []\n",
    "            for cid in range(num_clients):\n",
    "                # assign class `class_idx` to client `cid`\n",
    "                class_idx = cid % num_classes\n",
    "                current = set()\n",
    "                current.add(class_idx)\n",
    "                assigned_clients_per_class[class_idx] += 1\n",
    "                assigned_class_count = 1\n",
    "                while (assigned_class_count < num_classes_per_client):\n",
    "                    ind = np.random.randint(0, num_classes)\n",
    "                    if (ind not in current):\n",
    "                        assigned_class_count += 1\n",
    "                        current.add(ind)\n",
    "                        assigned_clients_per_class[ind] += 1\n",
    "                assigned_classes_per_client.append(current)\n",
    "\n",
    "        missing_classes = []\n",
    "        for k in range(num_classes):\n",
    "            if assigned_clients_per_class[k] == 0:\n",
    "                missing_classes.append(str(k))\n",
    "        if len(missing_classes) > 0:\n",
    "            warnings.warn(\"Classes \" + \",\".join(missing_classes) +\n",
    "                          \"are not used. Consider increase either num_clients or num_classes_per_client.\")\n",
    "        for k in range(num_classes):\n",
    "            idx_k = np.where(ylabels == k)[0]\n",
    "            np.random.shuffle(idx_k)\n",
    "            try:\n",
    "                split = np.array_split(idx_k, assigned_clients_per_class[k])\n",
    "            except ValueError:\n",
    "                pass\n",
    "            ids = 0\n",
    "            for cid in range(num_clients):\n",
    "                if k in assigned_classes_per_client[cid]:\n",
    "                    cid_idxlst_dict[cid] += split[ids].tolist()\n",
    "                    ids += 1\n",
    "        stats_dict['num_classes'] = num_classes\n",
    "        stats_dict['num_classes_per_client'] = num_classes_per_client\n",
    "        stats_dict['assigned_classes_per_client'] = assigned_classes_per_client\n",
    "        stats_dict['assigned_clients_per_class'] = assigned_clients_per_class\n",
    "    elif partition == 'noniid-label-distribution':\n",
    "        \"\"\"\n",
    "        The number of classes per client own follow a dirichlet distribution with concentration parameter beta.\n",
    "        feddf: https://github.com/epfml/federated-learning-public-code/blob/7e002ef5ff0d683dba3db48e2d088165499eb0b9/codes/FedDF-code/pcode/datasets/partition_data.py#L197\n",
    "        \"\"\"\n",
    "        if is_balanced:\n",
    "            np.random.seed(2022)\n",
    "            server_config = kwargs['server_config']\n",
    "            save_dir = f\"../experiments/datapartition/{server_config['dataset']}_{beta}b_{server_config['num_clients']}.pkl\"\n",
    "            print(\"Doing balanced dir sampling\")\n",
    "            if os.path.exists(save_dir):\n",
    "                print('Partition is found!')\n",
    "                cid_idxlst_dict = load_from_pkl(save_dir)\n",
    "            else:\n",
    "                n_data_per_clnt = int(num_samples / num_clients)\n",
    "                clnt_data_list = (np.ones(num_clients) * n_data_per_clnt).astype(int)\n",
    "                cls_priors = np.random.dirichlet(alpha=[beta] * num_classes, size=num_clients)\n",
    "                prior_cumsum = np.cumsum(cls_priors, axis=1)\n",
    "                idx_list = [np.where(ylabels == i)[0] for i in range(num_classes)]\n",
    "                cls_amount = [len(idx_list[i]) for i in range(num_classes)]\n",
    "                cid_idxlst_dict = {cid: [] for cid in range(num_clients)}\n",
    "                while(np.sum(clnt_data_list) != 0):\n",
    "                    curr_clnt = np.random.randint(num_clients)\n",
    "                    # If current node is full resample a client\n",
    "                    print('Remaining Data: %d' % np.sum(clnt_data_list))\n",
    "                    if clnt_data_list[curr_clnt] <= 0:\n",
    "                        continue\n",
    "                    clnt_data_list[curr_clnt] -= 1\n",
    "                    curr_prior = prior_cumsum[curr_clnt]\n",
    "                    while True:\n",
    "                        cls_label = np.argmax(np.random.uniform() <= curr_prior)\n",
    "                        # Redraw class label if trn_y is out of that class\n",
    "                        if cls_amount[cls_label] <= 0:\n",
    "                            continue\n",
    "                        cls_amount[cls_label] -= 1\n",
    "                        cid_idxlst_dict[curr_clnt].append(idx_list[cls_label][cls_amount[cls_label]])\n",
    "                        break\n",
    "                mkdirs('../experiments/datapartition/')\n",
    "                save_to_pkl(cid_idxlst_dict, save_dir)\n",
    "                print('cid_idxlst_dict is saved to', save_dir)\n",
    "        else:\n",
    "            resample = False\n",
    "            while cur_minsize < minsize or resample:\n",
    "                attemp += 1\n",
    "                if attemp > max_attemp:\n",
    "                    count = 0\n",
    "                    for cid in range(num_clients):\n",
    "                        if allocated_classes[cid] <= 1:\n",
    "                            count += 1\n",
    "                    print(f\" Warning: {count} clients have less than 2 classes\")\n",
    "                    break\n",
    "                batch_idxs = [[] for _ in range(num_clients)]\n",
    "                allocated_classes = [0] * num_clients\n",
    "                for k in range(num_classes):\n",
    "                    idx_k = np.where(ylabels == k)[0]\n",
    "                    np.random.shuffle(idx_k)\n",
    "                    # determine the fraction of samples in class k for each client;\n",
    "                    proportions = np.random.dirichlet(np.repeat(beta, num_clients))\n",
    "                    # if number of samples in client j is already larger than the threshold num_samples / num_clients\n",
    "                    # then the client won't contain any new class including the current class k\n",
    "                    proportions = np.array(\n",
    "                        [p * (len(allocated_idxs) < num_samples / num_clients) for p, allocated_idxs in zip(proportions, batch_idxs)])\n",
    "                    proportions = proportions / proportions.sum()\n",
    "                    stats_dict[f'proportions_{k}'] = proportions\n",
    "                    proportions_to_num = (np.cumsum(proportions) * len(idx_k)).astype(int)[:-1]\n",
    "                    # reference: https://numpy.org/doc/stable/reference/generated/numpy.split.html\n",
    "                    # batch_idxs = [allocated_idxs + idx.tolist() for allocated_idxs,\n",
    "                    #               idx in zip(batch_idxs, np.split(idx_k, proportions_to_num))]\n",
    "                    chunks = np.split(idx_k, proportions_to_num)\n",
    "                    # hack to fix class deficiency in some clients\n",
    "                    if k >= 2:\n",
    "                        if min(allocated_classes) <= 1:\n",
    "                            cid_has_only_one_or_less_class = []\n",
    "                            for cid in range(num_clients):\n",
    "                                if allocated_classes[cid] <= 1:\n",
    "                                    cid_has_only_one_or_less_class.append(cid)\n",
    "                            replace_index = -1\n",
    "                            for cid in cid_has_only_one_or_less_class:\n",
    "                                temp_chunk = chunks[cid]\n",
    "                                temp_ratio = proportions[cid]\n",
    "                                chunks[cid] = chunks[replace_index]\n",
    "                                chunks[replace_index] = temp_chunk\n",
    "                                proportions[cid] = proportions[replace_index]\n",
    "                                proportions[replace_index] = temp_ratio\n",
    "                                replace_index -= 1\n",
    "                    cid = 0\n",
    "                    for allocated_idxs, idx in zip(batch_idxs, chunks):\n",
    "                        added_samples = idx.tolist()\n",
    "                        if len(added_samples) > 0:\n",
    "                            allocated_idxs += added_samples\n",
    "                            allocated_classes[cid] += 1\n",
    "                        cid += 1\n",
    "                    cur_minsize = min([len(allocated_idxs)\n",
    "                                       for allocated_idxs in batch_idxs])\n",
    "                if min(allocated_classes) <= 1:\n",
    "                    resample = True\n",
    "                    print(\" [Info - Dirichlet Sampling]: At leaset one client only has one class label. Perform Resampling...\")\n",
    "                else:\n",
    "                    resample = False\n",
    "            cid_idxlst_dict = {cid: [] for cid in range(num_clients)}\n",
    "            for cid in range(num_clients):\n",
    "                np.random.shuffle(batch_idxs[cid])\n",
    "                cid_idxlst_dict[cid] = batch_idxs[cid]\n",
    "        stats_dict['num_classes'] = num_classes\n",
    "    elif partition == 'shards':\n",
    "        num_shards_per_client = kwargs['num_shards_per_client']\n",
    "        dict_users, stats_dict['rand_set_all'] = sshards(dataset, num_clients, num_shards_per_client, server_data_ratio=0.0, rand_set_all=[])\n",
    "        cid_idxlst_dict = {i: dict_users[i].tolist() for i in range(num_clients)}\n",
    "    else:\n",
    "        raise ValueError(f\"partition:{partition} is not recognized.\")\n",
    "    # generate a set of sub-datasets\n",
    "    dataset_per_client_dict = {\n",
    "        cid: DatasetSplit(dataset, cid_idxlst_dict[cid]) for cid in range(num_clients)}\n",
    "    stats_dict['num_clients'] = num_clients\n",
    "    stats_dict['partition'] = partition\n",
    "    stats_dict['seed'] = seed\n",
    "    stats_dict['minsize'] = minsize\n",
    "    return dataset_per_client_dict, stats_dict\n",
    "\n",
    "\n",
    "def sampler_reuse(dataset, stats_dict, **kwargs):\n",
    "    partition = stats_dict['partition']\n",
    "    num_clients = stats_dict['num_clients']\n",
    "    if stats_dict['seed'] is not None:\n",
    "        np.random.seed(stats_dict['seed'])\n",
    "    if partition in ['noniid-label-quantity', 'noniid-label-distribution']:\n",
    "        num_classes = stats_dict['num_classes']\n",
    "        num_unique_class = len(torch.unique(dataset.targets))\n",
    "        assert num_classes == num_unique_class, f\"num_class is set to, but number of unique class detected in ylables are {num_unique_class}. The dataset may have a different distribution!\"\n",
    "        if 'ylabels' not in kwargs:\n",
    "            raise ValueError(\n",
    "                f\"The ylabels parameter needs to be set for the partition {partition}.\")\n",
    "        else:\n",
    "            ylabels = kwargs['ylabels']\n",
    "    num_samples = len(dataset)\n",
    "    idxs = np.random.permutation(num_samples)\n",
    "    cur_minsize = 0\n",
    "    attemp = 0\n",
    "    max_attemp = 100\n",
    "    if partition == 'iid-equal-size':\n",
    "        batch_idxs = np.array_split(idxs, num_clients)\n",
    "        if len(batch_idxs[-1]) < stats_dict['minsize']:\n",
    "            warnings.warn(\n",
    "                f\"partition:{partition} | Some clients have less than {stats_dict['minsize']} samples. Check it before continue.\")\n",
    "        cid_idxlst_dict = {\n",
    "            cid: batch_idxs[cid].tolist() for cid in range(num_clients)}\n",
    "    elif partition == 'iid-diff-size':\n",
    "        proportions_to_num = (\n",
    "            np.cumsum(stats_dict['proportions']) * len(idxs)).astype(int)[:-1]\n",
    "        batch_idxs = np.split(idxs, proportions_to_num)\n",
    "        cid_idxlst_dict = {i: batch_idxs[i].tolist()\n",
    "                           for i in range(num_clients)}\n",
    "    elif partition == 'noniid-label-quantity':\n",
    "        num_classes_per_client = stats_dict['num_classes_per_client']\n",
    "        assert num_classes_per_client <= num_classes, \"`num_classes_per_client` should be no bigger than `num_classes`\"\n",
    "        cid_idxlst_dict = {cid: [] for cid in range(num_clients)}\n",
    "        for k in range(num_classes):\n",
    "            idx_k = np.where(ylabels == k)[0]\n",
    "            np.random.shuffle(idx_k)\n",
    "            try:\n",
    "                split = np.array_split(\n",
    "                    idx_k, stats_dict['assigned_clients_per_class'][k])\n",
    "            except ValueError:\n",
    "                pass\n",
    "            ids = 0\n",
    "            for cid in range(num_clients):\n",
    "                if k in stats_dict['assigned_classes_per_client'][cid]:\n",
    "                    cid_idxlst_dict[cid] += split[ids].tolist()\n",
    "                    ids += 1\n",
    "    elif partition == 'noniid-label-distribution':\n",
    "        batch_idxs = [[] for _ in range(num_clients)]\n",
    "        for k in range(num_classes):\n",
    "            idx_k = np.where(ylabels == k)[0]\n",
    "            np.random.shuffle(idx_k)\n",
    "            proportions = stats_dict[f'proportions_{k}']\n",
    "            proportions_to_num = (np.cumsum(proportions) *\n",
    "                                  len(idx_k)).astype(int)[:-1]\n",
    "            batch_idxs = [allocated_idxs + idx.tolist() for allocated_idxs,\n",
    "                          idx in zip(batch_idxs, np.split(idx_k, proportions_to_num))]\n",
    "\n",
    "        cid_idxlst_dict = {cid: [] for cid in range(num_clients)}\n",
    "        for cid in range(num_clients):\n",
    "            np.random.shuffle(batch_idxs[cid])\n",
    "            cid_idxlst_dict[cid] = batch_idxs[cid]\n",
    "    else:\n",
    "        raise ValueError(f\"partition:{partition} is not recognized.\")\n",
    "    # generate a set of sub-datasets\n",
    "    dataset_per_client_dict = {\n",
    "        cid: DatasetSplit(dataset, cid_idxlst_dict[cid]) for cid in range(num_clients)}\n",
    "    return dataset_per_client_dict\n",
    "\n",
    "\n",
    "def sshards(dataset, num_users, shard_per_user, server_data_ratio, rand_set_all=[]):\n",
    "    setup_seed(2022)\n",
    "    dict_users, all_idxs = {i: np.array([], dtype='int64') for i in range(num_users)}, [i for i in range(len(dataset))]\n",
    "\n",
    "    idxs_dict = {}\n",
    "    for i in range(len(dataset)):\n",
    "        label = dataset.targets[i].item()\n",
    "        if label not in idxs_dict.keys():\n",
    "            idxs_dict[label] = []\n",
    "        # collect all data in class ``label``\n",
    "        idxs_dict[label].append(i)\n",
    "\n",
    "    num_classes = len(np.unique(dataset.targets))\n",
    "    shard_per_class = int(shard_per_user * num_users / num_classes)\n",
    "    for label in idxs_dict.keys():\n",
    "        x = idxs_dict[label]\n",
    "        num_leftover = len(x) % shard_per_class\n",
    "        leftover = x[-num_leftover:] if num_leftover > 0 else []\n",
    "        x = np.array(x[:-num_leftover]) if num_leftover > 0 else np.array(x)\n",
    "        x = x.reshape((shard_per_class, -1))\n",
    "        x = list(x)\n",
    "\n",
    "        for i, idx in enumerate(leftover):\n",
    "            x[i] = np.concatenate([x[i], [idx]])\n",
    "        idxs_dict[label] = x\n",
    "\n",
    "    if len(rand_set_all) == 0:\n",
    "        rand_set_all = list(range(num_classes)) * shard_per_class\n",
    "        random.shuffle(rand_set_all)\n",
    "        rand_set_all = np.array(rand_set_all).reshape((num_users, -1))\n",
    "\n",
    "    # divide and assign\n",
    "    for i in range(num_users):\n",
    "        rand_set_label = rand_set_all[i]\n",
    "        rand_set = []\n",
    "        for label in rand_set_label:\n",
    "            idx = np.random.choice(len(idxs_dict[label]), replace=False)\n",
    "            rand_set.append(idxs_dict[label].pop(idx))\n",
    "        dict_users[i] = np.concatenate(rand_set)\n",
    "\n",
    "    test = []\n",
    "    for key, value in dict_users.items():\n",
    "        x = np.unique(dataset.targets[value])\n",
    "        assert(len(x)) <= shard_per_user\n",
    "        test.append(value)\n",
    "    test = np.concatenate(test)\n",
    "    assert(len(test) == len(dataset))\n",
    "    assert(len(set(list(test))) == len(dataset))\n",
    "\n",
    "    if server_data_ratio > 0.0:\n",
    "        dict_users['server'] = set(np.random.choice(all_idxs, int(len(dataset) * server_data_ratio), replace=False))\n",
    "    # print(dict_users)\n",
    "    # exit()\n",
    "    return dict_users, rand_set_all\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "visualization tools\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def visualize_sampling(dataset_per_client_dict, num_classes, figsize=(10, 8), **kwargs):\n",
    "    num_clients = len(dataset_per_client_dict)\n",
    "    mat = np.zeros((num_clients, num_classes))\n",
    "    targets = dataset_per_client_dict[0].dataset.targets\n",
    "    for key in dataset_per_client_dict.keys():\n",
    "        subset = dataset_per_client_dict[key]\n",
    "        for k in range(num_classes):\n",
    "            num_samples = torch.sum(torch.eq(targets[subset.idxs], k)).item()\n",
    "            mat[key, k] = num_samples\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "\n",
    "    im, _ = heatmap(mat, np.arange(num_clients), np.arange(num_classes), ax=ax,\n",
    "                    cmap=\"YlGn\", cbarlabel=\"#Samples\")\n",
    "    _ = annotate_heatmap(im, valfmt=\"{x:.0f}\")\n",
    "\n",
    "    fig.tight_layout()\n",
    "    if 'fig_path_name' in kwargs:\n",
    "        fig_path_name = kwargs['fig_path_name']\n",
    "        dirpath = \"/\".join(fig_path_name.split(\"/\")[:-1])\n",
    "        mkdirs(dirpath)\n",
    "        plt.savefig(fig_path_name)\n",
    "    else:\n",
    "        plt.show()\n",
    "    return mat\n",
    "\n",
    "\n",
    "def heatmap(data, x_labels, y_labels, ax=None,\n",
    "            cbar_kw={}, cbarlabel=\"\", **kwargs):\n",
    "\n",
    "    if not ax:\n",
    "        ax = plt.gca()\n",
    "\n",
    "    # Plot the heatmap\n",
    "    im = ax.imshow(data.T, **kwargs)\n",
    "\n",
    "    # Create colorbar\n",
    "    cbar = ax.figure.colorbar(im, ax=ax, **cbar_kw)\n",
    "    cbar.ax.set_ylabel(cbarlabel, rotation=-90, va=\"bottom\")\n",
    "\n",
    "#     # Show all ticks and label them with the respective list entries.\n",
    "    ax.set_xticks(np.arange(data.shape[0]))\n",
    "    ax.set_xticklabels(x_labels)\n",
    "    ax.set_xlabel(\"Client ID\")\n",
    "    ax.set_yticks(np.arange(data.shape[1]))\n",
    "    ax.set_yticklabels(y_labels)\n",
    "    ax.set_ylabel(\"Class label\")\n",
    "\n",
    "    ax.set_xticks(np.arange(data.shape[0] + 1) - .5, minor=True)\n",
    "    ax.set_yticks(np.arange(data.shape[1] + 1) - .5, minor=True)\n",
    "    ax.grid(which=\"minor\", color=\"w\", linestyle='-', linewidth=3)\n",
    "    ax.tick_params(which=\"minor\", bottom=False, left=False)\n",
    "\n",
    "    return im, cbar\n",
    "\n",
    "\n",
    "def annotate_heatmap(im, data=None, valfmt=\"{x:.2f}\",\n",
    "                     textcolors=(\"black\", \"white\"),\n",
    "                     threshold=None, **textkw):\n",
    "\n",
    "    if not isinstance(data, (list, np.ndarray)):\n",
    "        data = im.get_array()\n",
    "\n",
    "    # Normalize the threshold to the images color range.\n",
    "    if threshold is not None:\n",
    "        threshold = im.norm(threshold)\n",
    "    else:\n",
    "        threshold = im.norm(data.max()) / 2.\n",
    "\n",
    "    # Set default alignment to center, but allow it to be\n",
    "    # overwritten by textkw.\n",
    "    kw = dict(horizontalalignment=\"center\",\n",
    "              verticalalignment=\"center\")\n",
    "    kw.update(textkw)\n",
    "\n",
    "    # Get the formatter in case a string is supplied\n",
    "    if isinstance(valfmt, str):\n",
    "        valfmt = matplotlib.ticker.StrMethodFormatter(valfmt)\n",
    "\n",
    "    # Loop over the data and create a `Text` for each \"pixel\".\n",
    "    # Change the text's color depending on the data.\n",
    "    texts = []\n",
    "    for i in range(data.shape[0]):\n",
    "        for j in range(data.shape[1]):\n",
    "            kw.update(color=textcolors[int(im.norm(data[i, j]) > threshold)])\n",
    "            text = im.axes.text(j, i, valfmt(data[i, j], None), **kw)\n",
    "            texts.append(text)\n",
    "\n",
    "    return texts\n",
    "\n",
    "\n",
    "class MulGaussian(Dataset):\n",
    "    def __init__(self, mean_lst, n_lst):\n",
    "        k = len(mean_lst)\n",
    "        self.data = None\n",
    "        self.targets = None\n",
    "        for i in range(k):\n",
    "            m = MultivariateNormal(torch.tensor(mean_lst[i]), torch.eye(len(mean_lst[i])))\n",
    "            samples = m.sample(sample_shape=(n_lst[i],))\n",
    "            labels = torch.ones((n_lst[i],), dtype=torch.int32) * i\n",
    "            if i == 0:\n",
    "                self.data = samples\n",
    "                self.targets = labels\n",
    "            else:\n",
    "                self.data = torch.cat((self.data, samples))\n",
    "                self.targets = torch.cat((self.targets, labels))\n",
    "        self.targets = self.targets.type(torch.LongTensor)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        return self.data[idx], self.targets[idx]\n",
    "\n",
    "\n",
    "class Spiral(Dataset):\n",
    "    def __init__(self, n_lst, sigma=0.5):\n",
    "        k = len(n_lst)\n",
    "        self.data = None\n",
    "        self.targets = None\n",
    "        for i in range(k):\n",
    "            r = torch.linspace(1, 10, n_lst[i])  # radius\n",
    "            t = torch.linspace(i / k * 2 * torch.pi, (i + 1) / k * 2 * torch.pi, n_lst[i]) + torch.rand(n_lst[i]) * sigma\n",
    "            x = r * torch.sin(t)\n",
    "            y = r * torch.cos(t)\n",
    "            samples = torch.stack((x, y), 1)\n",
    "            labels = torch.ones((n_lst[i],), dtype=torch.int32) * i\n",
    "            if i == 0:\n",
    "                self.data = samples\n",
    "                self.targets = labels\n",
    "            else:\n",
    "                self.data = torch.cat((self.data, samples))\n",
    "                self.targets = torch.cat((self.targets, labels))\n",
    "        self.targets = self.targets.type(torch.LongTensor)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        return self.data[idx], self.targets[idx]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "TinyImageNet Dataset\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "EXTENSION = 'JPEG'\n",
    "NUM_IMAGES_PER_CLASS = 500\n",
    "CLASS_LIST_FILE = 'wnids.txt'\n",
    "VAL_ANNOTATION_FILE = 'val_annotations.txt'\n",
    "\n",
    "\n",
    "\n",
    "class TinyImageNet(Dataset):\n",
    "    \"\"\"\n",
    "    Ref: https://github.com/leemengtaiwan/tiny-imagenet/blob/master/TinyImageNet.py\n",
    "    Tiny ImageNet data set available from `http://cs231n.stanford.edu/tiny-imagenet-200.zip`.\n",
    "    Parameters\n",
    "    ----------\n",
    "    root: string\n",
    "        Root directory including `train`, `test` and `val` subdirectories.\n",
    "    split: string\n",
    "        Indicating which split to return as a data set.\n",
    "        Valid option: [`train`, `test`, `val`]\n",
    "    transform: torchvision.transforms\n",
    "        A (series) of valid transformation(s).\n",
    "    in_memory: bool\n",
    "        Set to True if there is enough memory (about 5G) and want to minimize disk IO overhead.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, root, split='train', transform=None, target_transform=None, in_memory=False):\n",
    "        self.root = os.path.expanduser(root)\n",
    "        self.split = split\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "        self.in_memory = in_memory\n",
    "        self.split_dir = os.path.join(self.root, self.split)\n",
    "        self.image_paths = sorted(glob.iglob(os.path.join(self.split_dir, '**', '*.%s' % EXTENSION), recursive=True))\n",
    "        self.labels = {}  # fname - label number mapping\n",
    "        self.images = []  # used for in-memory processing\n",
    "        # build class label - number mapping\n",
    "        with open(os.path.join(self.root, CLASS_LIST_FILE), 'r') as fp:\n",
    "            self.label_texts = sorted([text.strip() for text in fp.readlines()])\n",
    "        self.label_text_to_number = {text: i for i, text in enumerate(self.label_texts)}\n",
    "\n",
    "        if self.split == 'train':\n",
    "            for label_text, i in self.label_text_to_number.items():\n",
    "                for cnt in range(NUM_IMAGES_PER_CLASS):\n",
    "                    self.labels['%s_%d.%s' % (label_text, cnt, EXTENSION)] = i\n",
    "        elif self.split == 'val':\n",
    "            with open(os.path.join(self.split_dir, VAL_ANNOTATION_FILE), 'r') as fp:\n",
    "                for line in fp.readlines():\n",
    "                    terms = line.split('\\t')\n",
    "                    file_name, label_text = terms[0], terms[1]\n",
    "                    self.labels[file_name] = self.label_text_to_number[label_text]\n",
    "\n",
    "        # get targets\n",
    "        self.targets = []\n",
    "        for index in range(len(self.image_paths)):\n",
    "            file_path = self.image_paths[index]\n",
    "            label_numeral = self.labels[os.path.basename(file_path)]\n",
    "            self.targets.append(label_numeral)\n",
    "\n",
    "        # read all images into torch tensor in memory to minimize disk IO overhead\n",
    "        if self.in_memory:\n",
    "            self.images = [self.read_image(path) for path in self.image_paths]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        file_path = self.image_paths[index]\n",
    "\n",
    "        if self.in_memory:\n",
    "            img = self.images[index]\n",
    "        else:\n",
    "            img = self.read_image(file_path)\n",
    "\n",
    "        if self.split == 'test':\n",
    "            return img\n",
    "        else:\n",
    "            # file_name = file_path.split('/')[-1]\n",
    "            return img, self.labels[os.path.basename(file_path)]\n",
    "\n",
    "    def __repr__(self):\n",
    "        fmt_str = 'Dataset ' + self.__class__.__name__ + '\\n'\n",
    "        fmt_str += '    Number of datapoints: {}\\n'.format(self.__len__())\n",
    "        tmp = self.split\n",
    "        fmt_str += '    Split: {}\\n'.format(tmp)\n",
    "        fmt_str += '    Root Location: {}\\n'.format(self.root)\n",
    "        tmp = '    Transforms (if any): '\n",
    "        fmt_str += '{0}{1}\\n'.format(tmp, self.transform.__repr__().replace('\\n', '\\n' + ' ' * len(tmp)))\n",
    "        tmp = '    Target Transforms (if any): '\n",
    "        fmt_str += '{0}{1}'.format(tmp, self.target_transform.__repr__().replace('\\n', '\\n' + ' ' * len(tmp)))\n",
    "        return fmt_str\n",
    "\n",
    "    def read_image(self, path):\n",
    "        img = Image.open(path)\n",
    "        img = img.convert('RGB')\n",
    "        return self.transform(img) if self.transform else img\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "get datasets\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def get_datasets(datasetname, **kwargs):\n",
    "    invTrans = None\n",
    "    if datasetname == \"FashionMnist\":\n",
    "        transform = torchvision.transforms.Compose([\n",
    "            torchvision.transforms.ToTensor(),\n",
    "            torchvision.transforms.Normalize((0.1307,), (0.3081,))\n",
    "        ])\n",
    "        trainset = torchvision.datasets.FashionMNIST(root='./data', train=True,\n",
    "                                                     download=True, transform=transform)\n",
    "        testset = torchvision.datasets.FashionMNIST(root='./data', train=False,\n",
    "                                                    download=True, transform=transform)\n",
    "    elif datasetname == \"Cifar10\":\n",
    "        transform_train = transforms.Compose([\n",
    "            transforms.RandomCrop(32, padding=4),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            torchvision.transforms.ToTensor(),\n",
    "            torchvision.transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "        ])\n",
    "        transform_test = transforms.Compose([\n",
    "            torchvision.transforms.ToTensor(),\n",
    "            torchvision.transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "        ])\n",
    "        invTrans = transforms.Compose([transforms.Normalize(mean=[0., 0., 0.],\n",
    "                                                            std=[1 / 0.2023, 1 / 0.1994, 1 / 0.2010]),\n",
    "                                       transforms.Normalize(mean=[-0.4914, -0.4822, -0.4465],\n",
    "                                                            std=[1., 1., 1.]),\n",
    "                                       ])\n",
    "        trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                                download=True, transform=transform_train)\n",
    "        testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                               download=True, transform=transform_test)\n",
    "        trainset.targets = torch.tensor(trainset.targets)\n",
    "        testset.targets = torch.tensor(testset.targets)\n",
    "    elif datasetname == 'Cifar100':\n",
    "        transform_train = transforms.Compose([transforms.RandomCrop(32, padding=4),\n",
    "                                              transforms.RandomHorizontalFlip(),\n",
    "                                              transforms.ToTensor(),\n",
    "                                              transforms.Normalize(mean=[0.507, 0.487, 0.441],\n",
    "                                                                   std=[0.267, 0.256, 0.276])])\n",
    "        transform_test = transforms.Compose([transforms.ToTensor(),\n",
    "                                             transforms.Normalize(mean=[0.507, 0.487, 0.441],\n",
    "                                                                  std=[0.267, 0.256, 0.276])])\n",
    "\n",
    "        trainset = torchvision.datasets.CIFAR100(root='./data', train=True,\n",
    "                                                 download=True, transform=transform_train)\n",
    "        testset = torchvision.datasets.CIFAR100(root='./data', train=False,\n",
    "                                                download=True, transform=transform_test)\n",
    "        trainset.targets = torch.tensor(trainset.targets)\n",
    "        testset.targets = torch.tensor(testset.targets)\n",
    "\n",
    "    elif datasetname == \"TinyImageNet\":\n",
    "        transform_train = transforms.Compose([\n",
    "            transforms.RandomCrop(64, padding=4),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ])\n",
    "        transform_test = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ])\n",
    "        trainset = TinyImageNet(\"./data/tiny-imagenet-200\", 'train', transform=transform_train, in_memory=False)\n",
    "        testset = TinyImageNet(\"./data/tiny-imagenet-200\", 'val', transform=transform_test, in_memory=False)\n",
    "        trainset.targets = torch.tensor(trainset.targets)\n",
    "        testset.targets = torch.tensor(testset.targets)\n",
    "\n",
    "    elif datasetname == \"Cifar10Aug\":\n",
    "        \"\"\"\n",
    "            On Bridging Generic and Personalized Federated Learning for Image Classification impl \n",
    "        \"\"\"\n",
    "        transform_train = transforms.Compose([\n",
    "            transforms.RandomCrop(32, padding=4),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.491, 0.482, 0.447], std=[0.247, 0.243, 0.262]),\n",
    "        ])\n",
    "        transform_test = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.491, 0.482, 0.447], std=[0.247, 0.243, 0.262]),\n",
    "        ])\n",
    "        trainset = torchvision.datasets.CIFAR10(root='~/data', train=True,\n",
    "                                                download=True, transform=transform_train)\n",
    "        testset = torchvision.datasets.CIFAR10(root='~/data', train=False,\n",
    "                                               download=True, transform=transform_test)\n",
    "        trainset.targets = torch.tensor(trainset.targets)\n",
    "        testset.targets = torch.tensor(testset.targets)\n",
    "    elif datasetname == \"GanEnhancedCifar10\":\n",
    "        trainset = GanEnhancedCifar10(\n",
    "            kwargs['generator_path'],\n",
    "            kwargs['dataset'],\n",
    "            kwargs['upsample']\n",
    "        )\n",
    "        transform = transforms.Compose([\n",
    "            torchvision.transforms.ToTensor(),\n",
    "            torchvision.transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "        ])\n",
    "        testset = torchvision.datasets.CIFAR10(root='~/data', train=False,\n",
    "                                               download=True, transform=transform)\n",
    "        testset.targets = torch.tensor(testset.targets)\n",
    "    else:\n",
    "        raise ValueError(f\"Unrecognized dataset:{datasetname}\")\n",
    "\n",
    "    return trainset, testset, invTrans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def setup_optimizer(model, config, round):\n",
    "    if config['client_lr_scheduler'] == 'stepwise':\n",
    "        if round < config['num_rounds'] // 2:\n",
    "            lr = config['client_lr']\n",
    "        else:\n",
    "            lr = config['client_lr'] * 0.1\n",
    "\n",
    "    elif config['client_lr_scheduler'] == 'diminishing':\n",
    "        lr = config['client_lr'] * (config['lr_decay_per_round'] ** (round - 1))\n",
    "    else:\n",
    "        raise ValueError('unknown client_lr_scheduler')\n",
    "    if config['optimizer'] == 'SGD':\n",
    "        optimizer = torch.optim.SGD(filter(lambda p: p.requires_grad, model.parameters()),\n",
    "                                    lr=lr,\n",
    "                                    momentum=config['sgd_momentum'], weight_decay=config['sgd_weight_decay'])\n",
    "        # print('line 34: weight_decay=1e-3')\n",
    "    elif config['optimizer'] == 'Adam':\n",
    "        optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()),\n",
    "                                     lr=lr,\n",
    "                                     weight_decay=1e-5)\n",
    "    elif config['optimizer'] == 'RMSprop':\n",
    "        optimizer = torch.optim.RMSprop(filter(lambda p: p.requires_grad, model.parameters()),\n",
    "                                        lr=lr,\n",
    "                                        alpha=config['rmsprop_alpha'],\n",
    "                                        eps=1e-08,\n",
    "                                        weight_decay=config['rmsprop_weight_decay'],\n",
    "                                        momentum=config['rmsprop_momentum'])\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown optimizer{config['optimizer']}\")\n",
    "    return optimizer\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "client initialization\n",
    "\"\"\"\n",
    "def setup_clients(Client, trainset, testset, criterion, client_config_lst,client_pyus, **kwargs):\n",
    "    \"\"\"\n",
    "        Client is a class constructor.\n",
    "        A deepcopy is invoked such that each client has a unique model.\n",
    "        **kwargs:\n",
    "            weight_init: {'init.normal'}\n",
    "            mean: params for init.normal\n",
    "            std: 0.1\n",
    "    \"\"\"\n",
    "    num_clients = kwargs['server_config']['num_clients']\n",
    "    partition = kwargs['server_config']['partition']\n",
    "    num_classes = kwargs['server_config']['num_classes']\n",
    "    assert len(client_config_lst) == num_clients, \"Inconsistent num_clients and len(client_config_lst).\"\n",
    "    if 'noniid' == partition[:6]:\n",
    "        trainset_per_client_dict, stats_dict = sampler(trainset, num_clients, partition, ylabels=trainset.targets,\n",
    "                                                       num_classes=num_classes, **kwargs)\n",
    "        if testset is None:\n",
    "            testset_per_client_dict = {cid: None for cid in range(num_clients)}\n",
    "        else:\n",
    "            if kwargs['same_testset']:\n",
    "                testset_per_client_dict = {cid: testset for cid in range(num_clients)}\n",
    "            else:\n",
    "                testset_per_client_dict = sampler_reuse(testset, stats_dict, ylabels=testset.targets,\n",
    "                                                        num_classes=num_classes, **kwargs)\n",
    "    else:\n",
    "        trainset_per_client_dict, stats_dict = sampler(trainset, num_clients, partition, num_classes=num_classes, **kwargs)\n",
    "        if testset is None:\n",
    "            testset_per_client_dict = {cid: None for cid in range(num_clients)}\n",
    "        else:\n",
    "            if kwargs['same_testset']:\n",
    "                testset_per_client_dict = {cid: testset for cid in range(num_clients)}\n",
    "            else:\n",
    "                testset_per_client_dict = sampler_reuse(testset, stats_dict, num_classes=num_classes, **kwargs)\n",
    "#     print('trainset_per_client_dict',trainset_per_client_dict)\n",
    "    n_samples = {cid: len(dataset) for cid, dataset in trainset_per_client_dict.items()}\n",
    "#     print('n_samples',n_samples)\n",
    "    all_clients_dict = {}\n",
    "    for cid in range(num_clients):\n",
    "        # same initial weight\n",
    "        setup_seed(2022)\n",
    "        all_clients_dict[cid] = Client(device = client_pyus[cid],\n",
    "            criterion=criterion,\n",
    "            trainset=trainset_per_client_dict[cid],\n",
    "            testset=testset_per_client_dict[cid],\n",
    "            client_config=client_config_lst[cid],\n",
    "            cid=cid,\n",
    "            **kwargs)\n",
    "    # print(all_clients_dict[9].trainset.targets)\n",
    "    return all_clients_dict,n_samples\n",
    "                         \n",
    "def create_clients_from_existing_ones(Client, clients_dict, newtrainset, increment, criterion, **kwargs):\n",
    "    \"\"\"\n",
    "        Create new clients. All clients will maintain the same data distribution as specified in clients_dict.\n",
    "    \"\"\"\n",
    "    num_clients = len(clients_dict)\n",
    "    all_clients_dict = {}\n",
    "    if 'same_pool' not in kwargs:\n",
    "        same_pool = False\n",
    "    else:\n",
    "        same_pool = kwargs['same_pool']\n",
    "\n",
    "    if 'scale' not in kwargs:\n",
    "        scale = len(newtrainset) // increment - 1\n",
    "    else:\n",
    "        scale = kwargs['scale']\n",
    "\n",
    "    for cid in range(num_clients):\n",
    "        client = clients_dict[cid]\n",
    "        data_idxs = client.trainset.idxs\n",
    "        add_idxs = []\n",
    "        if same_pool:\n",
    "            for cls in client.count_by_class.keys():\n",
    "                num_sample_cls = client.count_by_class[cls]\n",
    "                target_num_sample_cls = min(num_sample_cls * scale, len(newtrainset.get_fake_imgs_idxs(cls)))\n",
    "                add_idxs += np.random.choice(newtrainset.get_fake_imgs_idxs(cls), target_num_sample_cls, replace=False).tolist()\n",
    "        else:\n",
    "            for i in data_idxs:\n",
    "                for j in range(scale):\n",
    "                    add_idxs.append(i + increment * (j + 1))\n",
    "\n",
    "        full_idxs = data_idxs + add_idxs\n",
    "        client_newtrainset = DatasetSplit(newtrainset, full_idxs)\n",
    "        all_clients_dict[cid] = Client(\n",
    "            criterion,\n",
    "            client_newtrainset,\n",
    "            client.testset,\n",
    "            client.client_config,\n",
    "            client.cid,\n",
    "            client.group,\n",
    "            client.device, **kwargs)\n",
    "    return all_clients_dict\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "resume training\n",
    "\"\"\"\n",
    "\n",
    "def resume_training(server_config, checkpoint, model):\n",
    "    server = load_from_pkl(checkpoint)\n",
    "    server.server_config = server_config\n",
    "    for c in server.clients_dict.values():\n",
    "        c.model = deepcopy(model)\n",
    "        c.set_params(server.server_model_state_dict)\n",
    "        c.model.to(c.device)\n",
    "        c.model.init()\n",
    "    print(\"Resume Training\")\n",
    "    print(f\"Rounds performed:{server.rounds}\")\n",
    "    return server\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "state_dict operation\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def scale_state_dict(this, scale, inplace=True, exclude=set()):\n",
    "    with torch.no_grad():\n",
    "        if not inplace:\n",
    "            ans = deepcopy(this)\n",
    "        else:\n",
    "            ans = this\n",
    "        for state_key in this.keys():\n",
    "            if state_key not in exclude:\n",
    "                ans[state_key] = this[state_key] * scale\n",
    "        return ans\n",
    "\n",
    "\n",
    "def linear_combination_state_dict(this, other, this_weight=1.0, other_weight=1.0, exclude=set()):\n",
    "    \"\"\"\n",
    "        this, other: state_dict\n",
    "        this_weight * this + other_weight * other \n",
    "    \"\"\"\n",
    "    with torch.no_grad():\n",
    "        ans = deepcopy(this)\n",
    "        for state_key in this.keys():\n",
    "            if state_key not in exclude:\n",
    "                # print('agg', state_key)\n",
    "                ans[state_key] = this[state_key] * this_weight + other[state_key] * other_weight\n",
    "        return ans\n",
    "\n",
    "\n",
    "def average_list_of_state_dict(state_dict_lst, exclude=set()):\n",
    "    assert type(state_dict_lst) == list\n",
    "    num_participants = len(state_dict_lst)\n",
    "    keys = state_dict_lst[0].keys()\n",
    "    with torch.no_grad():\n",
    "        ans = OrderedDict()\n",
    "        for key in keys:\n",
    "            if state_key not in exclude:\n",
    "                for idx, client_state_dict in enumerate(state_dict_lst):\n",
    "                    if idx == 0:\n",
    "                        # must do deepcopy; otherwise subsequent operation overwrittes the first client_state_dict\n",
    "                        ans[key] = deepcopy(client_state_dict[key])\n",
    "                    else:\n",
    "                        ans[key] += client_state_dict[key]\n",
    "                ans[key] = ans[key] / num_participants\n",
    "    return ans\n",
    "\n",
    "\n",
    "def weight_sum_of_dict_of_state_dict(dict_state_dict, weight_dict):\n",
    "    layer_keys = next(iter(dict_state_dict.values())).keys()\n",
    "    with torch.no_grad():\n",
    "        ans = OrderedDict()\n",
    "        for layer in layer_keys:\n",
    "            count = 0\n",
    "            for cid in dict_state_dict.keys():\n",
    "                if count == 0:\n",
    "                    # must do deepcopy; otherwise subsequent operation overwrittes the first client_state_dict\n",
    "                    ans[layer] = deepcopy(dict_state_dict[cid][layer]) * weight_dict[cid]\n",
    "                else:\n",
    "                    ans[layer] += dict_state_dict[cid][layer] * weight_dict[cid]\n",
    "                count += 1\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "定义了联邦学习场景下的客户端 FedPCGClient 类和服务器 FedPCGServer类，实现了基于聚类采样和全局原型的个性化联邦学习"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "metadata": {},
   "outputs": [],
   "source": [
    "@proxy(PYUObject)\n",
    "class FedPCGClient(Client):\n",
    "    def __init__(self, criterion, trainset, testset, client_config, cid, **kwargs):\n",
    "        super().__init__(criterion, trainset, testset,\n",
    "                         client_config, cid, **kwargs)\n",
    "        self._initialize_model()\n",
    "        self.device = 'cpu'\n",
    "        self.global_model = deepcopy(self.model)\n",
    "        self.client_config = client_config\n",
    "        self.beta = 1\n",
    "        self.tau = 0.5\n",
    "        self.num_classes = 10\n",
    "        self.criterion=nn.CrossEntropyLoss()\n",
    "        self.KLDiv = nn.KLDivLoss(reduction=\"batchmean\")\n",
    "        temp = [self.count_by_class[cls] if cls in self.count_by_class.keys() else 1e-12 for cls in\n",
    "                range(client_config['num_classes'])]\n",
    "        self.count_by_class_full = torch.tensor(temp).to(self.device)\n",
    "\n",
    "        self.global_model2 = deepcopy(self.model)\n",
    "    def get_model_named_parameters(self):\n",
    "        return list(self.model.named_parameters())\n",
    "\n",
    "    def _estimate_prototype(self,global_model2):\n",
    "        self.model.eval()\n",
    "        self.model.return_embedding = True\n",
    "        embedding_dim = self.model.prototype.shape[1]\n",
    "        prototype = torch.zeros_like(self.model.prototype)\n",
    "        self.set_gloabl_param(self.global_model2, global_model2)\n",
    "        self.global_model2.eval()\n",
    "        self.global_model2.return_embedding = True\n",
    "        with torch.no_grad():\n",
    "            for i, (x, y) in enumerate(self.trainloader):\n",
    "                # forward pass\n",
    "                x, y = x.to(self.device), y.to(self.device)\n",
    "                # feature_embedding is normalized,shape:[64,192]\n",
    "                feature_embedding, _ = self.model.forward(x)\n",
    "                feature_embedding_global, _ = self.global_model2.forward(x)\n",
    "                classes_shown_in_this_batch = torch.unique(y).cpu().numpy()\n",
    "                for cls in classes_shown_in_this_batch:\n",
    "                    mask = (y == cls)\n",
    "                    feature_embedding_in_cls = torch.sum(feature_embedding[mask, :], dim=0)\n",
    "                    feature_embedding_global_in_cls = torch.sum(feature_embedding_global[mask, :], dim=0)\n",
    "                    prototype[cls] +=  0.7 * feature_embedding_in_cls + 0.3 * feature_embedding_global_in_cls\n",
    "        for cls in self.count_by_class.keys():\n",
    "            # sample mean\n",
    "            prototype[cls] /= self.count_by_class[cls]\n",
    "            # normalization so that self.W.data is of the sampe scale as prototype_cls_norm\n",
    "            prototype_cls_norm = torch.norm(prototype[cls]).clamp(min=1e-12)\n",
    "            prototype[cls] = torch.div(prototype[cls], prototype_cls_norm)\n",
    "            # reweight it for aggregartion\n",
    "            prototype[cls] *= self.count_by_class[cls]\n",
    "\n",
    "        self.model.return_embedding = False\n",
    "\n",
    "        to_share = {'scaled_prototype': prototype, 'count_by_class_full': self.count_by_class_full}\n",
    "        return to_share\n",
    "\n",
    "    def _estimate_prototype_adv(self):\n",
    "        self.model.eval()\n",
    "        self.model.return_embedding = True\n",
    "        embeddings = []\n",
    "        labels = []\n",
    "        weights = []\n",
    "        prototype = torch.zeros_like(self.model.prototype)\n",
    "        with torch.no_grad():\n",
    "            for i, (x, y) in enumerate(self.trainloader):\n",
    "                # forward pass\n",
    "                x, y = x.to(self.device), y.to(self.device)\n",
    "                # feature_embedding is normalized\n",
    "                # use the latest prototype\n",
    "                feature_embedding, logits = self.model.forward(x)\n",
    "                prob_ = F.softmax(logits, dim=1)\n",
    "                prob = torch.gather(prob_, dim=1, index=y.view(-1, 1))\n",
    "                labels.append(y)\n",
    "                weights.append(prob)\n",
    "                embeddings.append(feature_embedding)\n",
    "        self.model.return_embedding = False\n",
    "        embeddings = torch.cat(embeddings, dim=0)\n",
    "        labels = torch.cat(labels, dim=0)\n",
    "        weights = torch.cat(weights, dim=0).view(-1, 1)\n",
    "        for cls in self.count_by_class.keys():\n",
    "            mask = (labels == cls)\n",
    "            weights_in_cls = weights[mask, :]\n",
    "            feature_embedding_in_cls = embeddings[mask, :]\n",
    "            prototype[cls] = torch.sum(feature_embedding_in_cls * weights_in_cls, dim=0) / torch.sum(weights_in_cls)\n",
    "            prototype_cls_norm = torch.norm(prototype[cls]).clamp(min=1e-12)\n",
    "            prototype[cls] = torch.div(prototype[cls], prototype_cls_norm)\n",
    "\n",
    "        # calculate predictive power\n",
    "        to_share = {'adv_agg_prototype': prototype, 'count_by_class_full': self.count_by_class_full}\n",
    "        return to_share\n",
    "    @staticmethod\n",
    "    def _get_orthonormal_basis(m, n):\n",
    "        \"\"\"\n",
    "            Each row of the the matrix is orthonormal\n",
    "        \"\"\"\n",
    "        W = torch.rand(m, n)\n",
    "        # gram schimdt\n",
    "        for i in range(m):\n",
    "            q = W[i, :]\n",
    "            for j in range(i):\n",
    "                q = q - torch.dot(W[j, :], W[i, :]) * W[j, :]\n",
    "            if torch.equal(q, torch.zeros_like(q)):\n",
    "                raise ValueError(\"The row vectors are not linearly independent!\")\n",
    "            q = q / torch.sqrt(torch.dot(q, q))\n",
    "            W[i, :] = q\n",
    "        return W\n",
    "    def setup_seed_local(self,seed):\n",
    "        random.seed(seed)\n",
    "        np.random.seed(seed)\n",
    "        torch.manual_seed(seed)\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "#         torch.backends.cudnn.deterministic = True\n",
    "    def _initialize_model(self):\n",
    "        # parse the model from config file\n",
    "        self.model = Conv2CifarNH(self.client_config).to(self.device)\n",
    "        # this is needed if the criterion has stateful tensors.\n",
    "        self.criterion = self.criterion.to(self.device)\n",
    "        try:\n",
    "            self.model.prototype.requires_grad_(False)\n",
    "            if self.client_config['FedNH_head_init'] == 'orthogonal':\n",
    "                # method 1:\n",
    "                # torch.nn.init.orthogonal_ has a bug when first called.\n",
    "                # self.model.prototype = torch.nn.init.orthogonal_(self.model.prototype)\n",
    "                # method 2: might be slow\n",
    "                # m, n = self.model.prototype.shape\n",
    "                # self.model.prototype.data = self._get_orthonormal_basis(m, n)\n",
    "                # method 3:\n",
    "                m, n = self.model.prototype.shape\n",
    "                self.model.prototype.data = torch.nn.init.orthogonal_(torch.rand(m, n)).to(self.device)\n",
    "            elif self.client_config['FedNH_head_init'] == 'uniform' and self.client_config['dim'] == 2:\n",
    "                r = 1.0\n",
    "                num_cls = self.client_config['num_classes']\n",
    "                W = torch.zeros(num_cls, 2)\n",
    "                for i in range(num_cls):\n",
    "                    theta = i * 2 * torch.pi / num_cls\n",
    "                    W[i, :] = torch.tensor([r * math.cos(theta), r * math.sin(theta)])\n",
    "                self.model.prototype.copy_(W)\n",
    "            else:\n",
    "                raise NotImplementedError(\n",
    "                    f\"{self.client_config['FedNH_head_init']} + {self.client_config['num_classes']}d\")\n",
    "        except AttributeError:\n",
    "            raise NotImplementedError(\"Only support linear layers now.\")\n",
    "        if self.client_config['FedNH_fix_scaling'] == True:\n",
    "            # 30.0 is a common choice in the paper\n",
    "            self.model.scaling.requires_grad_(False)\n",
    "            self.model.scaling.data = torch.tensor(30.0).to(self.device)\n",
    "            print('self.model.scaling.data:', self.model.scaling.data)\n",
    "\n",
    "    def set_gloabl_param(self,g1,g2):\n",
    "        with torch.no_grad():\n",
    "            for key in g2.keys():\n",
    "                g1.state_dict()[key].copy_(g2[key])\n",
    "\n",
    "    def training(self, round, num_epochs,global_model):\n",
    "        \"\"\"\n",
    "            Note that in order to use the latest server side model the `set_params` method should be called before `training` method.\n",
    "        \"\"\"\n",
    "#         setup_seed(round + self.client_config['global_seed'])\n",
    "        print('Begin local training!')\n",
    "        train_start = time.time()\n",
    "        self.setup_seed_local(round)\n",
    "        # train mode\n",
    "        self.model.train()\n",
    "        # tracking stats\n",
    "        self.set_gloabl_param(self.global_model,global_model)\n",
    "        self.global_model = self.global_model.eval().requires_grad_(False)\n",
    "        self.num_rounds_particiapted += 1\n",
    "        loss_seq = []\n",
    "        acc_seq = []\n",
    "        if self.trainloader is None:\n",
    "            raise ValueError(\"No trainloader is provided!\")\n",
    "        optimizer = setup_optimizer(self.model, self.client_config, round)\n",
    "        # print('lr:', optimizer.param_groups[0]['lr'])\n",
    "        # training starts\n",
    "        for i in range(num_epochs):\n",
    "            epoch_loss, correct = 0.0, 0\n",
    "            for _, (x, y) in enumerate(self.trainloader):\n",
    "                # forward pass\n",
    "                x, y = x.to(self.device), y.to(self.device)\n",
    "                yhat = self.model.forward(x)\n",
    "                loss = self.criterion(yhat, y)\n",
    "                y_g = self.global_model.forward(x)\n",
    "                loss += self._ntd_loss(yhat, y_g, y) * self.beta\n",
    "                # backward pass\n",
    "                # model.zero_grad safer and memory-efficient\n",
    "                self.model.zero_grad(set_to_none=True)\n",
    "                loss.backward()\n",
    "                torch.nn.utils.clip_grad_norm_(parameters=filter(lambda p: p.requires_grad, self.model.parameters()), max_norm=10)\n",
    "                optimizer.step()\n",
    "                # stats\n",
    "                predicted = yhat.data.max(1)[1]\n",
    "                correct += predicted.eq(y.data).sum().item()\n",
    "                epoch_loss += loss.item() * x.shape[0]  # rescale to bacthsize\n",
    "\n",
    "            epoch_loss /= len(self.trainloader.dataset)\n",
    "            epoch_accuracy = correct / len(self.trainloader.dataset)\n",
    "            loss_seq.append(epoch_loss)\n",
    "            acc_seq.append(epoch_accuracy)\n",
    "        self.new_state_dict = self.model.state_dict()\n",
    "        self.train_loss_dict[round] = loss_seq\n",
    "        self.train_acc_dict[round] = acc_seq\n",
    "        print('Local training completed!')\n",
    "        train_time = time.time() - train_start\n",
    "        print(f\"Local training time:{train_time:.3f} seconds\")\n",
    "    def get_train_loss_dict(self,r):\n",
    "        return self.train_loss_dict[r]\n",
    "    def get_train_acc_dict(self,r):\n",
    "        return self.train_acc_dict[r]\n",
    "    def get_test_loss_dict(self,r):\n",
    "        return self.test_loss_dict[r]\n",
    "    def get_test_acc_dict(self,r):\n",
    "        return self.test_acc_dict[r]\n",
    "    def get_num_train_samples(self):\n",
    "        return self.num_train_samples\n",
    "    def get_testloader(self):\n",
    "        return self.testloader\n",
    "    def _ntd_loss(self, logits, dg_logits, targets):\n",
    "        \"\"\"Not-tue Distillation Loss\"\"\"\n",
    "\n",
    "        # Get smoothed local model prediction\n",
    "        logits = refine_as_not_true(logits, targets, self.num_classes)\n",
    "        pred_probs = F.log_softmax(logits / self.tau, dim=1)\n",
    "\n",
    "        # Get smoothed global model prediction\n",
    "        with torch.no_grad():\n",
    "            dg_logits = refine_as_not_true(dg_logits, targets, self.num_classes)\n",
    "            dg_probs = torch.softmax(dg_logits / self.tau, dim=1)\n",
    "\n",
    "        loss = (self.tau ** 2) * self.KLDiv(pred_probs, dg_probs)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def upload(self, global_model2):\n",
    "        if self.client_config['FedNH_client_adv_prototype_agg']:\n",
    "            return self.new_state_dict, self._estimate_prototype_adv()\n",
    "        else:\n",
    "            return self.new_state_dict, self._estimate_prototype(global_model2)\n",
    "\n",
    "    def testing(self, round, testloader=None):\n",
    "        self.model.eval()\n",
    "        if testloader is None:\n",
    "            testloader = self.testloader\n",
    "        test_count_per_class = Counter(testloader.dataset.targets.numpy())\n",
    "        # all_classes_sorted = sorted(test_count_per_class.keys())\n",
    "        # test_count_per_class = torch.tensor([test_count_per_class[cls] * 1.0 for cls in all_classes_sorted])\n",
    "        # num_classes = len(all_classes_sorted)\n",
    "        num_classes = self.client_config['num_classes']\n",
    "        test_count_per_class = torch.tensor([test_count_per_class[cls] * 1.0 for cls in range(num_classes)])\n",
    "        test_correct_per_class = torch.tensor([0] * num_classes)\n",
    "\n",
    "        weight_per_class_dict = {'uniform': torch.tensor([1.0] * num_classes),\n",
    "                                 'validclass': torch.tensor([0.0] * num_classes),\n",
    "                                 'labeldist': torch.tensor([0.0] * num_classes)}\n",
    "        for cls in self.label_dist.keys():\n",
    "            weight_per_class_dict['labeldist'][cls] = self.label_dist[cls]\n",
    "            weight_per_class_dict['validclass'][cls] = 1.0\n",
    "        # start testing\n",
    "        with torch.no_grad():\n",
    "            for i, (x, y) in enumerate(testloader):\n",
    "                # forward pass\n",
    "                x, y = x.to(self.device), y.to(self.device)\n",
    "                yhat = self.model.forward(x)\n",
    "                # stats\n",
    "                predicted = yhat.data.max(1)[1]\n",
    "                classes_shown_in_this_batch = torch.unique(y).cpu().numpy()\n",
    "                for cls in classes_shown_in_this_batch:\n",
    "                    test_correct_per_class[cls] += ((predicted == y) * (y == cls)).sum().item()\n",
    "        acc_by_critertia_dict = {}\n",
    "        for k in weight_per_class_dict.keys():\n",
    "            acc_by_critertia_dict[k] = (((weight_per_class_dict[k] * test_correct_per_class).sum()) /\n",
    "                                        ((weight_per_class_dict[k] * test_count_per_class).sum())).item()\n",
    "\n",
    "        self.test_acc_dict[round] = {'acc_by_criteria': acc_by_critertia_dict,\n",
    "                                     'correct_per_class': test_correct_per_class,\n",
    "                                     'weight_per_class': weight_per_class_dict}\n",
    "                    \n",
    "def refine_as_not_true(logits, targets, num_classes):\n",
    "    nt_positions = torch.arange(0, num_classes).to(logits.device)\n",
    "    nt_positions = nt_positions.repeat(logits.size(0), 1)\n",
    "    nt_positions = nt_positions[nt_positions[:, :] != targets.view(-1, 1)]\n",
    "    nt_positions = nt_positions.view(-1, num_classes - 1)\n",
    "\n",
    "    logits = torch.gather(logits, 1, nt_positions)\n",
    "\n",
    "    return logits\n",
    "\n",
    "                    \n",
    "@proxy(PYUObject)                  \n",
    "class FedPCGServer(Server):\n",
    "    def __init__(self,n_samples,server_config, clients_dict,exclude,**kwargs):\n",
    "        super().__init__(server_config, clients_dict, **kwargs)  \n",
    "        \n",
    "#         print('kwargs',**kwargs)\n",
    "        self.device = 'cpu'\n",
    "        self.summary_setup()\n",
    "        self.server_model_state_dict = deepcopy(self.clients_dict[0].get_params())\n",
    "#         print('server_param',self.server_model_state_dict)\n",
    "        # make sure the starting point is correct\n",
    "        self.server_side_client.set_params(self.server_model_state_dict.to(self.server_side_client.device), exclude_keys=set())\n",
    "        self.exclude_layer_keys = set()\n",
    "        for key in sf.reveal(self.server_model_state_dict):\n",
    "            for ekey in exclude:\n",
    "                if ekey in key:\n",
    "                    self.exclude_layer_keys.add(key)\n",
    "        if len(self.exclude_layer_keys) > 0:\n",
    "            print(f\"{self.server_config['strategy']}Server: the following keys will not be aggregated:\\n \", self.exclude_layer_keys)\n",
    "        freeze_layers = []\n",
    "        for param in sf.reveal(self.server_side_client.get_model_named_parameters()):\n",
    "            if param[1].requires_grad == False:\n",
    "                freeze_layers.append(param[0])\n",
    "        if len(freeze_layers) > 0:\n",
    "            print(\"Server: the following layers will not be updated:\", freeze_layers)\n",
    "        self.selection = ClusteredSampling2(server_config['num_clients'],'cpu','L1')\n",
    "        self.nsamples = n_samples\n",
    "#         print('n_samples',self.nsamples)\n",
    "        self.selection.setup(self.nsamples)\n",
    "    \n",
    "    \n",
    "    def aggregate(self, client_uploads,round):\n",
    "        \n",
    "        server_lr = self.server_config['learning_rate'] * (self.server_config['lr_decay_per_round'] ** (round - 1))\n",
    "        num_participants = len(client_uploads)\n",
    "        update_direction_state_dict = None\n",
    "        # agg weights for prototype shape:[10,]\n",
    "        cumsum_per_class = torch.zeros(server_config['num_classes'])\n",
    "        agg_weights_vec_dict = {}\n",
    "        with torch.no_grad():\n",
    "            for idx, (client_state_dict, prototype_dict) in enumerate(sf.reveal(client_uploads)):\n",
    "                if self.server_config['FedNH_server_adv_prototype_agg'] == False:\n",
    "                    cumsum_per_class += prototype_dict['count_by_class_full']\n",
    "                else:\n",
    "                    mu = prototype_dict['adv_agg_prototype']\n",
    "                    W = self.server_model_state_dict['prototype']\n",
    "                    agg_weights_vec_dict[idx] = torch.exp(torch.sum(W * mu, dim=1, keepdim=True))\n",
    "                client_update = linear_combination_state_dict(sf.reveal(client_state_dict),\n",
    "                                                              sf.reveal(self.server_model_state_dict),\n",
    "                                                              1.0,\n",
    "                                                              -1.0,\n",
    "                                                              exclude=self.exclude_layer_keys\n",
    "                                                              )\n",
    "                if idx == 0:\n",
    "                    update_direction_state_dict = client_update\n",
    "                else:\n",
    "                    update_direction_state_dict = linear_combination_state_dict(sf.reveal(update_direction_state_dict),\n",
    "                                                                                sf.reveal(client_update),\n",
    "                                                                                1.0,\n",
    "                                                                                1.0,\n",
    "                                                                                exclude=self.exclude_layer_keys\n",
    "                                                                                )\n",
    "            # new feature extractor\n",
    "            self.server_model_state_dict = linear_combination_state_dict(sf.reveal(self.server_model_state_dict),\n",
    "                                                                         sf.reveal(update_direction_state_dict),\n",
    "                                                                         1.0,\n",
    "                                                                         server_lr / num_participants,\n",
    "                                                                         exclude=self.exclude_layer_keys\n",
    "                                                                         )\n",
    "\n",
    "            avg_prototype = torch.zeros_like(self.server_model_state_dict['prototype'])\n",
    "            if self.server_config['FedNH_server_adv_prototype_agg'] == False:\n",
    "                for _, prototype_dict in sf.reveal(client_uploads):\n",
    "                    avg_prototype += prototype_dict['scaled_prototype']  / cumsum_per_class.view(-1, 1)\n",
    "\n",
    "            else:\n",
    "                m = self.server_model_state_dict['prototype'].shape[0]\n",
    "                sum_of_weights = torch.zeros((m, 1)).to(avg_prototype.device)\n",
    "                for idx, (_, prototype_dict) in enumerate(client_uploads):\n",
    "                    sum_of_weights += agg_weights_vec_dict[idx]\n",
    "                    avg_prototype += agg_weights_vec_dict[idx] * prototype_dict['adv_agg_prototype']\n",
    "                avg_prototype /= sum_of_weights\n",
    "\n",
    "            # normalize prototype avg_prototype.shape:[10,192]\n",
    "            avg_prototype = F.normalize(avg_prototype, dim=1)\n",
    "            # update prototype with moving average\n",
    "            weight = self.server_config['FedNH_smoothing']\n",
    "            temp = weight * self.server_model_state_dict['prototype'] + (1 - weight) * avg_prototype\n",
    "\n",
    "            # print('agg weight:', weight)\n",
    "            # normalize prototype again\n",
    "            self.server_model_state_dict['prototype'].copy_(F.normalize(temp, dim=1))\n",
    "\n",
    "    def testing(self, round, active_only=True, **kwargs):\n",
    "        \"\"\"\n",
    "        active_only: only compute statiscs with to the active clients only\n",
    "        \"\"\"\n",
    "        # get the latest global model\n",
    "        self.server_side_client.set_params(self.server_model_state_dict, self.exclude_layer_keys)\n",
    "\n",
    "        # test the performance for global models\n",
    "        self.server_side_client.testing(round, testloader=None)  # use global testdataset\n",
    "        print(' server global model correct', torch.sum(sf.reveal(self.server_side_client.get_test_acc_dict(round))['correct_per_class']).item())\n",
    "        # test the performance for local models (potentiallt only for active local clients)\n",
    "        client_indices = self.clients_dict.keys()\n",
    "        if active_only:\n",
    "            client_indices = self.active_clients_indicies\n",
    "        for cid in client_indices:\n",
    "            client = self.clients_dict[cid]\n",
    "            # test local model on the splitted testset\n",
    "            if self.server_config['split_testset'] == True:\n",
    "                client.testing(round, None)\n",
    "            else:\n",
    "                # test local model on the global testset\n",
    "                client.testing(round, self.server_side_client.get_testloader().to(client.device))\n",
    "    def setup_seed_global(self,seed):\n",
    "        random.seed(seed)\n",
    "        np.random.seed(seed)\n",
    "        torch.manual_seed(seed)\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "    def collect_stats(self, stage, round, active_only, **kwargs):\n",
    "        \"\"\"\n",
    "            No actual training and testing is performed. Just collect stats.\n",
    "            stage: str;\n",
    "                {\"train\", \"test\"}\n",
    "            active_only: bool;\n",
    "                True: compute stats on active clients only\n",
    "                False: compute stats on all clients\n",
    "        \"\"\"\n",
    "        # get client_indices\n",
    "        client_indices = self.clients_dict.keys()\n",
    "        if active_only:\n",
    "            client_indices = self.active_clients_indicies\n",
    "        total_loss = 0.0\n",
    "        total_acc = 0.0\n",
    "        total_samples = 0\n",
    "        if stage == 'train':\n",
    "            for cid in client_indices:\n",
    "                client = self.clients_dict[cid]\n",
    "                # client.train_loss_dict[round] is a list compose the training loss per end of each epoch\n",
    "                loss, acc, num_samples = sf.reveal(client.get_train_loss_dict(round))[-1], sf.reveal(client.get_train_acc_dict(round))[-1], client.get_num_train_samples()\n",
    "                total_loss += loss * sf.reveal(num_samples)\n",
    "                total_acc += acc * sf.reveal(num_samples)\n",
    "                total_samples += sf.reveal(num_samples)\n",
    "            average_loss, average_acc = total_loss / total_samples, total_acc / total_samples\n",
    "            self.average_train_loss_dict[round] = average_loss\n",
    "            self.average_train_acc_dict[round] = average_acc\n",
    "        else:\n",
    "            # test stage\n",
    "            # get global model performance\n",
    "            self.gfl_test_acc_dict[round] = self.server_side_client.get_test_acc_dict(round)\n",
    "            acc_criteria = sf.reveal(self.server_side_client.get_test_acc_dict(round))['acc_by_criteria'].keys()\n",
    "            # get local model average performance\n",
    "            self.average_pfl_test_acc_dict[round] = {key: 0.0 for key in acc_criteria}\n",
    "            for cid in client_indices:\n",
    "                client = self.clients_dict[cid]\n",
    "                acc_by_criteria_dict = sf.reveal(client.get_test_acc_dict(round))['acc_by_criteria']\n",
    "                for key in acc_criteria:\n",
    "                    self.average_pfl_test_acc_dict[round][key] += acc_by_criteria_dict[key]\n",
    "\n",
    "            num_participants = len(client_indices)\n",
    "            for key in acc_criteria:\n",
    "                self.average_pfl_test_acc_dict[round][key] /= num_participants\n",
    "    def client_selection(self):\n",
    "        # client_indices = self.clients_dict.keys()\n",
    "        client_indices = [*range(self.server_config['num_clients'])]\n",
    "        n = int(self.server_config['num_clients'] * self.server_config['participate_ratio'])\n",
    "        selected_client_indices = self.selection.select(n,client_indices)\n",
    "        return selected_client_indices\n",
    "    def run(self, device,**kwargs):\n",
    "        if self.server_config['use_tqdm']:\n",
    "            round_iterator = tqdm(range(self.rounds + 1, self.server_config['num_rounds'] + 1), desc=\"Round Progress\")\n",
    "        else:\n",
    "            round_iterator = range(self.rounds + 1, self.server_config['num_rounds'] + 1)\n",
    "        # round index begin with 1\n",
    "        for r in round_iterator:\n",
    "            self.setup_seed_global(r)\n",
    "            if r==1:\n",
    "                selected_indices = self.select_clients(self.server_config['participate_ratio'])\n",
    "            else:\n",
    "                selected_indices = self.client_selection()\n",
    "            if self.server_config['drop_ratio'] > 0:\n",
    "                # mimic the stragler issues; simply drop them\n",
    "                self.active_clients_indicies = np.random.choice(selected_indices, int(\n",
    "                    len(selected_indices) * (1 - self.server_config['drop_ratio'])), replace=False)\n",
    "            else:\n",
    "                self.active_clients_indicies = selected_indices\n",
    "            # active clients download weights from the server\n",
    "            tqdm.write(f\"Round:{r} - Active clients:{self.active_clients_indicies}:\")\n",
    "            for cid in self.active_clients_indicies:\n",
    "                client = self.clients_dict[cid]\n",
    "                client.set_params(sf.reveal(self.server_model_state_dict), self.exclude_layer_keys)\n",
    "\n",
    "            # clients perform local training\n",
    "            \n",
    "            client_uploads = []\n",
    "            for cid in self.active_clients_indicies:\n",
    "                client = self.clients_dict[cid]\n",
    "                client.training(r, client_config['num_epochs'],sf.reveal(self.server_model_state_dict))\n",
    "                client_upload = client.upload(sf.reveal(self.server_model_state_dict))\n",
    "#                 print('client_uploads',client_uploads)\n",
    "                client_uploads.append(client_upload.to(device))\n",
    "            \n",
    "            local_models = [self.clients_dict[cid].get_model().to(device) for cid in range(self.server_config['num_clients'])]\n",
    "            self.selection.init(self.server_model_state_dict, local_models)\n",
    "\n",
    "            # collect training stats\n",
    "            # average train loss and acc over active clients, where each client uses the latest local models\n",
    "            self.collect_stats(stage=\"train\", round=r, active_only=True)\n",
    "\n",
    "            # get new server model\n",
    "            # agg_start = time.time()\n",
    "            self.aggregate(client_uploads,round=r)\n",
    "            # agg_time = time.time() - agg_start\n",
    "            # print(f\" Aggregation time:{agg_time:.3f} seconds\")\n",
    "            # collect testing stats\n",
    "            if (r - 1) % self.server_config['test_every'] == 0:\n",
    "                test_start = time.time()\n",
    "                self.testing(round=r, active_only=True)\n",
    "                test_time = time.time() - test_start\n",
    "                print(f\" Testing time:{test_time:.3f} seconds\")\n",
    "                self.collect_stats(stage=\"test\", round=r, active_only=True)\n",
    "                print(\" avg_test_acc:\", sf.reveal(self.gfl_test_acc_dict[r])['acc_by_criteria'])\n",
    "                print(\" pfl_avg_test_acc:\", self.average_pfl_test_acc_dict[r])\n",
    "                if len(self.gfl_test_acc_dict) >= 2:\n",
    "                    current_key = r\n",
    "                    if sf.reveal(self.gfl_test_acc_dict[current_key])['acc_by_criteria']['uniform'] > best_test_acc:\n",
    "                        best_test_acc = sf.reveal(self.gfl_test_acc_dict[current_key])['acc_by_criteria']['uniform']\n",
    "                        self.server_model_state_dict_best_so_far = deepcopy(self.server_model_state_dict)\n",
    "                        tqdm.write(f\" Best test accuracy:{float(best_test_acc):5.3f}. Best server model is updatded and saved at {kwargs['filename']}!\")\n",
    "                        if 'filename' in kwargs:\n",
    "                            torch.save(sf.reveal(self.server_model_state_dict_best_so_far), kwargs['filename'])\n",
    "                else:\n",
    "                    best_test_acc = sf.reveal(self.gfl_test_acc_dict[r])['acc_by_criteria']['uniform']\n",
    "            # wandb monitoring\n",
    "            if kwargs['use_wandb']:\n",
    "                stats = {\"avg_train_loss\": self.average_train_loss_dict[r],\n",
    "                         \"avg_train_acc\": self.average_train_acc_dict[r],\n",
    "                         \"gfl_test_acc_uniform\": self.gfl_test_acc_dict[r]['acc_by_criteria']['uniform']\n",
    "                         }\n",
    "\n",
    "                for criteria in self.average_pfl_test_acc_dict[r].keys():\n",
    "                    stats[f'pfl_test_acc_{criteria}'] = self.average_pfl_test_acc_dict[r][criteria]\n",
    "\n",
    "                wandb.log(stats)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "隐语环境下FedPCG的实现流程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-26 18:06:52,465\tINFO worker.py:1538 -- Started a local Ray instance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "results are saved in:  ./Cifar_FedPCG/\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Create proxy actor <class '__main__.FedPCGClient'> with party client_0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainset_per_client_dict {0: <__main__.DatasetSplit object at 0x7f7308af5700>, 1: <__main__.DatasetSplit object at 0x7f7308af5520>, 2: <__main__.DatasetSplit object at 0x7f7308af5190>, 3: <__main__.DatasetSplit object at 0x7f7308af50d0>, 4: <__main__.DatasetSplit object at 0x7f7308af5640>}\n",
      "n_samples {0: 10752, 1: 10258, 2: 12094, 3: 10009, 4: 6887}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Create proxy actor <class '__main__.FedPCGClient'> with party client_1.\n",
      "INFO:root:Create proxy actor <class '__main__.FedPCGClient'> with party client_2.\n",
      "INFO:root:Create proxy actor <class '__main__.FedPCGClient'> with party client_3.\n",
      "INFO:root:Create proxy actor <class '__main__.FedPCGClient'> with party client_4.\n",
      "INFO:root:Create proxy actor <class '__main__.FedPCGServer'> with party server.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ClientCstr <class '__main__.ActorProxy(FedPCGClient)'>\n",
      "Strategy Related Hyper-parameters:\n",
      "server side\n",
      "client side\n",
      "\u001b[2m\u001b[36m(FedPCGClient pid=100998)\u001b[0m cuda is not available. use cpu instead.\n",
      "\u001b[2m\u001b[36m(FedPCGClient pid=101060)\u001b[0m cuda is not available. use cpu instead.\n",
      "\u001b[2m\u001b[36m(FedPCGClient pid=101122)\u001b[0m cuda is not available. use cpu instead.\n",
      "\u001b[2m\u001b[36m(FedPCGClient pid=101186)\u001b[0m cuda is not available. use cpu instead.\n",
      "\u001b[2m\u001b[36m(FedPCGClient pid=101261)\u001b[0m cuda is not available. use cpu instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(FedPCGServer pid=101352)\u001b[0m INFO:root:Create proxy actor <class 'types.FedPCGClient'> with party fake_client.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(FedPCGServer pid=101352)\u001b[0m ==============================Run Summary==============================\n",
      "\u001b[2m\u001b[36m(FedPCGServer pid=101352)\u001b[0m Dataset:\n",
      "\u001b[2m\u001b[36m(FedPCGServer pid=101352)\u001b[0m  dataset:Cifar10 | num_classes:10 | partition:noniid-label-distribution | beta:0.3\n",
      "\u001b[2m\u001b[36m(FedPCGServer pid=101352)\u001b[0m Server Info:\n",
      "\u001b[2m\u001b[36m(FedPCGServer pid=101352)\u001b[0m  strategy:FedPCG | num_clients:5 | num_rounds: 200 | participate_ratio:0.6 | drop_ratio:0.0\n",
      "\u001b[2m\u001b[36m(FedPCGServer pid=101352)\u001b[0m Clients Info:\n",
      "\u001b[2m\u001b[36m(FedPCGServer pid=101352)\u001b[0m  model:Conv2Cifar | num_epochs:5 | batch_size:64 | optimizer:SGD | inint lr:0.01 | lr scheduler:diminishing | momentum: 0.9 | weight decay: 1e-05\n",
      "\u001b[2m\u001b[36m(FedPCGServer pid=101352)\u001b[0m Server: the following layers will not be updated: ['prototype']\n",
      "\u001b[2m\u001b[36m(FedPCGServer pid=101352)\u001b[0m n_samples {0: 10752, 1: 10258, 2: 12094, 3: 10009, 4: 6887}\n",
      "\u001b[2m\u001b[36m(FedPCGServer pid=101352)\u001b[0m n_samples [10752 10258 12094 10009  6887]\n",
      "\u001b[2m\u001b[36m(FedPCGServer pid=101352)\u001b[0m Round:1 - Active clients:[2 1 4]:\n",
      "\u001b[2m\u001b[36m(FedPCGClient pid=101454)\u001b[0m cuda is not available. use cpu instead.\n",
      "\u001b[2m\u001b[36m(FedPCGClient pid=101060)\u001b[0m Begin local training!\n",
      "\u001b[2m\u001b[36m(FedPCGClient pid=101122)\u001b[0m Begin local training!\n",
      "\u001b[2m\u001b[36m(FedPCGClient pid=101261)\u001b[0m Begin local training!\n",
      "\u001b[2m\u001b[36m(FedPCGClient pid=101261)\u001b[0m Local training completed!\n",
      "\u001b[2m\u001b[36m(FedPCGClient pid=101261)\u001b[0m Local training time:64.330 seconds\n",
      "\u001b[2m\u001b[36m(FedPCGClient pid=101060)\u001b[0m Local training completed!\n",
      "\u001b[2m\u001b[36m(FedPCGClient pid=101060)\u001b[0m Local training time:94.166 seconds\n",
      "\u001b[2m\u001b[36m(FedPCGClient pid=101122)\u001b[0m Local training completed!\n",
      "\u001b[2m\u001b[36m(FedPCGClient pid=101122)\u001b[0m Local training time:109.097 seconds\n",
      "\u001b[2m\u001b[36m(FedPCGServer pid=101352)\u001b[0m  server global model correct 3841\n",
      "\u001b[2m\u001b[36m(FedPCGServer pid=101352)\u001b[0m  Testing time:5.541 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(FedPCGServer pid=101352)\u001b[0m \r",
      ">> similarity: 0it [00:00, ?it/s]\r",
      ">> similarity: 25it [00:00, 21256.36it/s]\n",
      "\u001b[2m\u001b[36m(FedPCGServer pid=101352)\u001b[0m /tmp/ipykernel_1222/2414577770.py:99: ClusterWarning: scipy.cluster: The symmetric non-negative hollow observation matrix looks suspiciously like an uncondensed distance matrix\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(FedPCGServer pid=101352)\u001b[0m  avg_test_acc: {'uniform': 0.3840999901294708, 'validclass': 0.3840999901294708, 'labeldist': 0.3841000199317932}\n",
      "\u001b[2m\u001b[36m(FedPCGServer pid=101352)\u001b[0m  pfl_avg_test_acc: {'uniform': 0.3190333346525828, 'validclass': 0.4337249994277954, 'labeldist': 0.7121689319610596}\n",
      "\u001b[2m\u001b[36m(FedPCGServer pid=101352)\u001b[0m (3, 5)\n",
      "\u001b[2m\u001b[36m(FedPCGServer pid=101352)\u001b[0m Round:2 - Active clients:[1 0 2]:\n",
      "\u001b[2m\u001b[36m(FedPCGClient pid=100998)\u001b[0m Begin local training!\n",
      "\u001b[2m\u001b[36m(FedPCGClient pid=101060)\u001b[0m Begin local training!\n",
      "\u001b[2m\u001b[36m(FedPCGClient pid=101122)\u001b[0m Begin local training!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2025-04-26 18:09:52,382 E 99499 99499] (raylet) node_manager.cc:3097: 1 Workers (tasks / actors) killed due to memory pressure (OOM), 0 Workers crashed due to other reasons at node (ID: 3d4dd8e970355fe922430e22b7f14df01a4bbf2d7d0a73017a9bca43, IP: 172.25.236.255) over the last time period. To see more information about the Workers killed on this node, use `ray logs raylet.out -ip 172.25.236.255`\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m Refer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(FedPCGClient pid=101060)\u001b[0m Local training completed!\n",
      "\u001b[2m\u001b[36m(FedPCGClient pid=101060)\u001b[0m Local training time:93.759 seconds\n",
      "\u001b[2m\u001b[36m(FedPCGClient pid=100998)\u001b[0m Local training completed!\n",
      "\u001b[2m\u001b[36m(FedPCGClient pid=100998)\u001b[0m Local training time:100.886 seconds\n",
      "\u001b[2m\u001b[36m(FedPCGClient pid=101122)\u001b[0m Local training completed!\n",
      "\u001b[2m\u001b[36m(FedPCGClient pid=101122)\u001b[0m Local training time:112.601 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-26 18:11:24,307\tERROR worker.py:400 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): \u001b[36mray::FedPCGServer.run()\u001b[39m (pid=101352, ip=172.25.236.255, repr=<__main__.FedPCGServer object at 0x7fd83373b880>)\n",
      "  File \"/home/user/anaconda3/envs/sf/lib/python3.8/site-packages/secretflow/device/proxy.py\", line 76, in wrapper\n",
      "    return method(*args, **kwargs)\n",
      "  File \"/tmp/ipykernel_1222/938230468.py\", line 509, in run\n",
      "  File \"/home/user/anaconda3/envs/sf/lib/python3.8/site-packages/secretflow/device/proxy.py\", line 76, in wrapper\n",
      "    return method(*args, **kwargs)\n",
      "  File \"/tmp/ipykernel_1222/938230468.py\", line 392, in testing\n",
      "  File \"/home/user/anaconda3/envs/sf/lib/python3.8/site-packages/secretflow/device/driver.py\", line 162, in reveal\n",
      "    all_object = sfd.get(all_object_refs)\n",
      "  File \"/home/user/anaconda3/envs/sf/lib/python3.8/site-packages/secretflow/distributed/primitive.py\", line 158, in get\n",
      "    return ray.get(object_refs)\n",
      "ray.exceptions.RayActorError: The actor died unexpectedly before finishing this task.\n",
      "\tclass_name: FedPCGClient\n",
      "\tactor_id: cdf9c7bda67c8de96bbb7dee01000000\n",
      "\tpid: 101454\n",
      "\tnamespace: 361e278e-0cbc-4a2b-a57c-d8088b09fd31\n",
      "\tip: 172.25.236.255\n",
      "The actor is dead because its worker process has died. Worker exit type: NODE_OUT_OF_MEMORY Worker exit detail: Task was killed due to the node running low on memory.\n",
      "Memory on the node (IP: 172.25.236.255, ID: 3d4dd8e970355fe922430e22b7f14df01a4bbf2d7d0a73017a9bca43) where the task (actor ID: cdf9c7bda67c8de96bbb7dee01000000, name=FedPCGClient.__init__, pid=101454, memory used=0.37GB) was running was 7.28GB / 7.64GB (0.952636), which exceeds the memory usage threshold of 0.95. Ray killed this worker (ID: 13ec99e97963f41786ab91943c27d64952301ae972b1fb5adf29fdda) because it was the most recently scheduled task; to see more information about memory usage on this node, use `ray logs raylet.out -ip 172.25.236.255`. To see the logs of the worker, use `ray logs worker-13ec99e97963f41786ab91943c27d64952301ae972b1fb5adf29fdda*out -ip 172.25.236.255. Top 10 memory users:\n",
      "PID\tMEM(GB)\tCOMMAND\n",
      "101352\t0.74\tray::FedPCGServer.run\n",
      "101122\t0.57\tray::FedPCGClient.training\n",
      "101060\t0.55\tray::FedPCGClient.training\n",
      "100998\t0.55\tray::FedPCGClient.training\n",
      "101261\t0.53\tray::FedPCGClient\n",
      "101186\t0.46\tray::FedPCGClient\n",
      "101454\t0.37\tray::FedPCGClient\n",
      "1222\t0.33\t/home/user/anaconda3/envs/sf/bin/python -m ipykernel_launcher -f /run/user/1000/jupyter/kernel-854e1...\n",
      "1169\t0.14\t/opt/google/chrome/chrome --type=renderer --string-annotations --crashpad-handler-pid=0 --enable-cra...\n",
      "99687\t0.06\tray::IDLE\n",
      "Refer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. Set max_restarts and max_task_retries to enable retry when the task crashes due to OOM. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.\n"
     ]
    }
   ],
   "source": [
    "import secretflow as sf\n",
    "sf.shutdown()\n",
    "num_clients = server_config['num_clients']\n",
    "sf.init([f\"client_{i}\" for i in range(server_config['num_clients'])] + [\"server\"]+[\"fake_client\"],address=\"local\")\n",
    "# cudnn_benchmark = True\n",
    "\n",
    "if args.strategy == 'FedAvg':\n",
    "    ClientCstr, ServerCstr = FedAvgClient, FedAvgServer\n",
    "    hyper_params = None\n",
    "\n",
    "elif args.strategy == 'FedNH':\n",
    "    ClientCstr, ServerCstr = FedNHClient, FedNHServer\n",
    "    server_config['FedNH_smoothing'] = args.FedNH_smoothing\n",
    "    server_config['FedNH_server_adv_prototype_agg'] = args.FedNH_server_adv_prototype_agg\n",
    "    client_config['FedNH_client_adv_prototype_agg'] = args.FedNH_client_adv_prototype_agg\n",
    "    hyper_params = f\"FedNH_smoothing:{args.FedNH_smoothing}_FedNH_client_adv_prototype_agg:{args.FedNH_client_adv_prototype_agg}\"\n",
    "\n",
    "elif args.strategy == 'FedPCG':\n",
    "    ClientCstr, ServerCstr = FedPCGClient, FedPCGServer\n",
    "    server_config['FedNH_smoothing'] = args.FedNH_smoothing\n",
    "    server_config['FedNH_server_adv_prototype_agg'] = args.FedNH_server_adv_prototype_agg\n",
    "    client_config['FedNH_client_adv_prototype_agg'] = args.FedNH_client_adv_prototype_agg\n",
    "    hyper_params = f\"FedNH_smoothing:{args.FedNH_smoothing}_FedNH_client_adv_prototype_agg:{args.FedNH_client_adv_prototype_agg}\"\n",
    "else:\n",
    "    raise ValueError(\"Invalid strategy!\")\n",
    "\n",
    "directory = f\"./{args.purpose}_{server_config['strategy']}/\"\n",
    "mkdirs(directory)\n",
    "# path = directory + run_tag\n",
    "path = directory\n",
    "print('results are saved in: ', path)\n",
    "client_config_lst = [client_config for i in range(args.num_clients)]\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "trainset, testset, _ = get_datasets(server_config['dataset'])\n",
    "client_pyus = [sf.PYU(f\"client_{i}\") for i in range(num_clients)]\n",
    "server_pyu = sf.PYU(\"server\")\n",
    "# setup clients\n",
    "if server_config['split_testset'] == False:\n",
    "    clients_dict,n_samples = setup_clients(ClientCstr, trainset, None, criterion,\n",
    "                                 client_config_lst, client_pyus,\n",
    "                                 server_config=server_config,\n",
    "                                 beta=server_config['beta'],\n",
    "                                 num_classes_per_client=server_config['num_classes_per_client'],\n",
    "                                 num_shards_per_client=server_config['num_shards_per_client'],\n",
    "                                 )\n",
    "else:\n",
    "    print('split test set!')\n",
    "    clients_dict,n_samples = setup_clients(ClientCstr, trainset, testset, criterion,\n",
    "                                 client_config_lst, client_pyus,\n",
    "                                 server_config=server_config,\n",
    "                                 beta=server_config['beta'],\n",
    "                                 num_classes_per_client=server_config['num_classes_per_client'],\n",
    "                                 num_shards_per_client=server_config['num_shards_per_client'],\n",
    "                                 same_testset=False\n",
    "                                 )\n",
    "\n",
    "# print('clients:',clients_dict)\n",
    "# setup server and run\n",
    "if args.strategy != 'Local':\n",
    "    print('ClientCstr',ClientCstr)\n",
    "    server = FedPCGServer(n_samples=n_samples,device=server_pyu,server_config=server_config, clients_dict=clients_dict, exclude=server_config['exclude'],\n",
    "                        server_side_criterion=criterion, global_testset=testset, global_trainset=trainset,\n",
    "                        client_cstr=ClientCstr, server_side_client_config=client_config, server_side_client_device=args.device)\n",
    "#     print('server:',server)\n",
    "    print('Strategy Related Hyper-parameters:')\n",
    "    print('server side')\n",
    "    for k in server_config.keys():\n",
    "        if args.strategy in k:\n",
    "            print(' ', k, \":\", server_config[k])\n",
    "    print('client side')\n",
    "    for k in client_config.keys():\n",
    "        if args.strategy in k:\n",
    "            print(' ', k, \":\", client_config[k])\n",
    "    server.run(device=server.device,filename=path + '_best_global_model.pkl', use_wandb=use_wandb, global_seed=args.global_seed)\n",
    "#     server.save(filename=path + '_final_server_obj.pkl', keep_clients_model=sf.reveal(args.keep_clients_model))\n",
    "else:\n",
    "    expected_num_rounds = int(server_config['num_rounds'] * server_config['participate_ratio'])\n",
    "    init_weight = clients_dict[0].get_params()\n",
    "    global_testloader = DataLoader(testset, batch_size=128, shuffle=False)\n",
    "    for cid in clients_dict.keys():\n",
    "        print(f\"Progress:{cid}/{len(clients_dict)}\")\n",
    "        client = clients_dict[cid]\n",
    "        client.set_params(init_weight, exclude_keys=set())\n",
    "        for r in range(1, expected_num_rounds + 1):\n",
    "            setup_seed(r + args.global_seed)\n",
    "            client.training(r, client.client_config['num_epochs'])\n",
    "            client.testing(r, global_testloader)\n",
    "            print(f\"Round: {r}/{expected_num_rounds}\", client.test_acc_dict[r]['acc_by_criteria'])\n",
    "        client.model = None\n",
    "        client.trainloader = None\n",
    "        client.trainset = None\n",
    "        client.new_state_dict = None\n",
    "    save_to_pkl(clients_dict, path + '_final_clients_dict.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FedProto",
   "language": "python",
   "name": "fedproto"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
